#!/usr/bin/env python3
"""
MCP-Local-Reader ç¼“å­˜å·¥å…·
ç”¨äºæŸ¥çœ‹æœ¬åœ°æ–‡ä»¶ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯ã€ç®¡ç†ç¼“å­˜å’Œåˆ†æç¼“å­˜æ€§èƒ½
"""

import os
import shutil
import argparse
from pathlib import Path
from typing import Dict, Any, Optional, List
import json

from src.file_reader.storage import LocalFileStorageClient
from src.file_reader.parsed_cache import get_parsed_cache
from src.file_reader.utils import get_logger

logger = get_logger("cache_utils")


def show_clear_warning():
    """æ˜¾ç¤ºæ¸…ç†è­¦å‘Šä¿¡æ¯"""
    print("âš ï¸  æ¸…ç†ç¼“å­˜è­¦å‘Š")
    print("=" * 50)
    print("æ¸…ç†ç¼“å­˜å°†åˆ é™¤ä»¥ä¸‹å†…å®¹:")
    print("  ğŸ“  æœ¬åœ°ç¼“å­˜ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶")
    print("  ğŸ’¾  æœ¬åœ°æ–‡ä»¶ç¼“å­˜")
    print("  ğŸ“„  è§£æç»“æœç¼“å­˜å’Œå›¾åƒOCRç¼“å­˜")
    print("  â€¢ æ¸…ç†åçš„é¦–æ¬¡è®¿é—®å¯èƒ½è¾ƒæ…¢")
    print()
    print("ç¼“å­˜æ¸…ç†çš„å¥½å¤„:")
    print("  ğŸ”„  é‡Šæ”¾ç£ç›˜ç©ºé—´")
    print("  ğŸ›  è§£å†³ç¼“å­˜æŸåé—®é¢˜")
    print("  ğŸ”§  æµ‹è¯•å’Œè°ƒè¯•")
    print("  âš¡  å¼ºåˆ¶é‡æ–°å¤„ç†æœ€æ–°å†…å®¹")
    print()


def confirm_clear_action() -> bool:
    """ç¡®è®¤æ¸…ç†æ“ä½œ"""
    show_clear_warning()
    
    print("\nğŸ” å®‰å…¨ç¡®è®¤")
    print("å¦‚æœæ‚¨ç¡®å®šè¦æ¸…ç†ç¼“å­˜ï¼Œè¯·è¾“å…¥: CLEAR CACHE CONFIRM")
    print("ä»»ä½•å…¶ä»–è¾“å…¥éƒ½å°†å–æ¶ˆæ“ä½œ")
    
    user_input = input("\nè¯·è¾“å…¥ç¡®è®¤æ–‡æœ¬: ").strip()
    
    if user_input == "CLEAR CACHE CONFIRM":
        print("âœ… ç¡®è®¤è¾“å…¥æ­£ç¡®ï¼Œå¼€å§‹æ¸…ç†ç¼“å­˜...")
        return True
    else:
        print("âŒ ç¡®è®¤æ–‡æœ¬ä¸åŒ¹é…ï¼Œå–æ¶ˆæ¸…ç†æ“ä½œ")
        return False


def clear_local_storage_cache():
    """æ¸…ç†æœ¬åœ°æ–‡ä»¶å­˜å‚¨å®¢æˆ·ç«¯çš„ç¼“å­˜"""
    try:
        # ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæœ¬åœ°å­˜å‚¨å®¢æˆ·ç«¯
        local_client = LocalFileStorageClient()
        
        # æ˜¾ç¤ºæ¸…ç†å‰çš„ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = local_client.get_stats()
        print(f"æ¸…ç†å‰çš„æœ¬åœ°æ–‡ä»¶ç¼“å­˜ç»Ÿè®¡:")
        print(f"  ç¼“å­˜é¡¹æ•°: {stats.get('cache_size', 0)}")
        print(f"  æœ¬åœ°ç¼“å­˜æ¡ç›®: {stats.get('local_cache_entries', 0)}")
        print(f"  ç¼“å­˜å‘½ä¸­ç‡: {stats.get('cache_hit_rate', 0):.2%}")
        print(f"  æ€»ç¼“å­˜å¤§å°: {format_size(stats.get('total_cached_bytes', 0))}")
        print(f"  è¯»å–æ¬¡æ•°: {stats.get('reads', 0)}")
        print(f"  ç¼“å­˜å‘½ä¸­: {stats.get('cache_hits', 0)}")
        print(f"  ç¼“å­˜æœªå‘½ä¸­: {stats.get('cache_misses', 0)}")
        
        local_client.clear_cache()
        logger.info("æœ¬åœ°æ–‡ä»¶å­˜å‚¨å®¢æˆ·ç«¯ç¼“å­˜å·²æ¸…ç†")
        return True
    except Exception as e:
        logger.error(f"æ¸…ç†æœ¬åœ°æ–‡ä»¶å­˜å‚¨ç¼“å­˜å¤±è´¥: {e}")
        return False




def clear_parsed_content_cache():
    """æ¸…ç†è§£æç»“æœç¼“å­˜"""
    try:
        parsed_cache = get_parsed_cache()
        
        # æ˜¾ç¤ºæ¸…ç†å‰çš„ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        stats = parsed_cache.get_cache_stats()
        print(f"æ¸…ç†å‰çš„è§£æç»“æœç¼“å­˜ç»Ÿè®¡:")
        print(f"  ç¼“å­˜é¡¹æ•°: {stats.get('total_items', 0)}")
        print(f"  ç¼“å­˜å‘½ä¸­ç‡: {stats.get('cache_hit_rate', 0):.2%}")
        print(f"  æ€»å†…å®¹å¤§å°: {format_size(stats.get('total_content_size', 0))}")
        print(f"  ç¼“å­˜å‘½ä¸­: {stats.get('cache_hits', 0)}")
        print(f"  ç¼“å­˜æœªå‘½ä¸­: {stats.get('cache_misses', 0)}")
        print(f"  ç¼“å­˜å†™å…¥: {stats.get('cache_writes', 0)}")
        print(f"  ç¼“å­˜é”™è¯¯: {stats.get('cache_errors', 0)}")
        print(f"  æœ‰æ•ˆæœŸ: {stats.get('expire_days', 30)}å¤©")
        
        parsed_cache.clear_cache()
        logger.info("è§£æç»“æœç¼“å­˜å·²æ¸…ç†")
        return True
    except Exception as e:
        logger.error(f"æ¸…ç†è§£æç»“æœç¼“å­˜å¤±è´¥: {e}")
        return False


def clear_directory_cache(cache_dir: str):
    """æ¸…ç†æŒ‡å®šç›®å½•çš„ç¼“å­˜"""
    try:
        cache_path = Path(cache_dir)
        if cache_path.exists():
            size_before = get_cache_size(cache_dir)
            shutil.rmtree(cache_path)
            logger.info(f"ç›®å½•ç¼“å­˜å·²æ¸…ç†: {cache_dir} (é‡Šæ”¾ {format_size(size_before)})")
            return True
        else:
            logger.info(f"ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
            return True
    except Exception as e:
        logger.error(f"æ¸…ç†ç›®å½•ç¼“å­˜å¤±è´¥ {cache_dir}: {e}")
        return False


def get_cache_size(cache_dir: str) -> int:
    """è·å–ç¼“å­˜ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
    try:
        cache_path = Path(cache_dir)
        if not cache_path.exists():
            return 0
        
        total_size = 0
        for file_path in cache_path.rglob('*'):
            if file_path.is_file():
                total_size += file_path.stat().st_size
        
        return total_size
    except Exception:
        return 0


def get_cache_file_count(cache_dir: str) -> int:
    """è·å–ç¼“å­˜ç›®å½•æ–‡ä»¶æ•°é‡"""
    try:
        cache_path = Path(cache_dir)
        if not cache_path.exists():
            return 0
        
        file_count = 0
        for file_path in cache_path.rglob('*'):
            if file_path.is_file():
                file_count += 1
        
        return file_count
    except Exception:
        return 0


def format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"


def show_cache_stats():
    """æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    print("ğŸ“Š MCP-Local-Reader ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 50)
    
    # æ˜¾ç¤ºæœ¬åœ°æ–‡ä»¶å­˜å‚¨å®¢æˆ·ç«¯ç»Ÿè®¡
    print("\nğŸ’» æœ¬åœ°æ–‡ä»¶å­˜å‚¨å®¢æˆ·ç«¯ç¼“å­˜:")
    try:
        local_client = LocalFileStorageClient()
        local_stats = local_client.get_stats()
        
        local_key_stats = [
            ('æ€»è¯»å–æ¬¡æ•°', 'reads'),
            ('ç¼“å­˜å‘½ä¸­æ¬¡æ•°', 'cache_hits'),
            ('ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°', 'cache_misses'),
            ('ç¼“å­˜å‘½ä¸­ç‡', 'cache_hit_rate'),
            ('æ€»è¯»å–å¤§å°', 'total_size'),
            ('é”™è¯¯æ¬¡æ•°', 'errors'),
            ('ç¼“å­˜é¡¹æ•°', 'cache_size'),
            ('æœ¬åœ°ç¼“å­˜æ¡ç›®', 'local_cache_entries'),
            ('æ€»ç¼“å­˜å¤§å°', 'total_cached_bytes'),
        ]
        
        for label, key in local_key_stats:
            if key in local_stats:
                value = local_stats[key]
                if key in ['cache_hit_rate']:
                    print(f"  {label}: {value:.2%}")
                elif key in ['total_size', 'total_cached_bytes']:
                    print(f"  {label}: {format_size(value)}")
                else:
                    print(f"  {label}: {value}")
        
        if 'cache_directory' in local_stats and local_stats['cache_directory']:
            print(f"  ç¼“å­˜ç›®å½•: {local_stats['cache_directory']}")
        if 'cache_size_limit' in local_stats:
            print(f"  ç¼“å­˜å¤§å°é™åˆ¶: {format_size(local_stats['cache_size_limit'])}")
        if 'allowed_directories' in local_stats:
            print(f"  å…è®¸çš„ç›®å½•æ•°: {len(local_stats['allowed_directories'])}")
        if 'allow_absolute_paths' in local_stats:
            print(f"  å…è®¸ç»å¯¹è·¯å¾„: {'æ˜¯' if local_stats['allow_absolute_paths'] else 'å¦'}")
        
    except Exception as e:
        logger.error(f"è·å–æœ¬åœ°æ–‡ä»¶å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {e}")
        print("  âŒ æ— æ³•è·å–æœ¬åœ°æ–‡ä»¶ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
    
    
    # æ˜¾ç¤ºè§£æç»“æœç¼“å­˜ç»Ÿè®¡
    print("\nğŸ“„ è§£æç»“æœç¼“å­˜:")
    try:
        parsed_cache = get_parsed_cache()
        parsed_stats = parsed_cache.get_cache_stats()
        
        parsed_key_stats = [
            ('ç¼“å­˜å‘½ä¸­æ¬¡æ•°', 'cache_hits'),
            ('ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°', 'cache_misses'),
            ('ç¼“å­˜å†™å…¥æ¬¡æ•°', 'cache_writes'),
            ('ç¼“å­˜é”™è¯¯æ¬¡æ•°', 'cache_errors'),
            ('ç¼“å­˜å‘½ä¸­ç‡', 'cache_hit_rate'),
            ('æ€»ç¼“å­˜é¡¹æ•°', 'total_items'),
            ('æ€»å†…å®¹å¤§å°', 'total_content_size'),
        ]
        
        for label, key in parsed_key_stats:
            if key in parsed_stats:
                value = parsed_stats[key]
                if key in ['cache_hit_rate']:
                    print(f"  {label}: {value:.2%}")
                elif key in ['total_content_size']:
                    print(f"  {label}: {format_size(value)}")
                else:
                    print(f"  {label}: {value}")
        
        if 'cache_directory' in parsed_stats and parsed_stats['cache_directory']:
            print(f"  ç¼“å­˜ç›®å½•: {parsed_stats['cache_directory']}")
        if 'cache_size_limit' in parsed_stats:
            print(f"  ç¼“å­˜å¤§å°é™åˆ¶: {format_size(parsed_stats['cache_size_limit'])}")
        if 'expire_days' in parsed_stats:
            print(f"  ç¼“å­˜æœ‰æ•ˆæœŸ: {parsed_stats['expire_days']}å¤©")
        
        # æ˜¾ç¤ºè§£æå™¨ç»Ÿè®¡
        if parsed_stats.get('parser_stats'):
            print(f"  è§£æå™¨ç»Ÿè®¡:")
            for parser, stats in parsed_stats['parser_stats'].items():
                print(f"    {parser}: {stats['count']}é¡¹, {format_size(stats['total_size'])}")
        
        # æ˜¾ç¤ºæ–‡æ¡£ç±»å‹ç»Ÿè®¡
        if parsed_stats.get('doc_type_stats'):
            print(f"  æ–‡æ¡£ç±»å‹ç»Ÿè®¡:")
            for doc_type, stats in parsed_stats['doc_type_stats'].items():
                print(f"    {doc_type}: {stats['count']}é¡¹, {format_size(stats['total_size'])}")
        
    except Exception as e:
        logger.error(f"è·å–è§£æç»“æœç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
        print("  âŒ æ— æ³•è·å–è§£æç»“æœç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
    
    # æ˜¾ç¤ºç›®å½•ç¼“å­˜å¤§å°
    cache_directories = [
        "cache/parsed_content",      # è§£æç»“æœç¼“å­˜
        "cache/document_images",     # å›¾åƒç¼“å­˜
        "cache/archive_files",       # å‹ç¼©æ–‡ä»¶ç¼“å­˜
        "cache",                     # æ€»ç¼“å­˜ç›®å½•
        "__pycache__",               # Pythonç¼“å­˜
        "src/file_reader/__pycache__",
        "src/file_reader/parsers/__pycache__",
    ]
    
    print(f"\nğŸ“ ç¼“å­˜ç›®å½•è¯¦æƒ…:")
    total_size = 0
    total_files = 0
    
    for cache_dir in cache_directories:
        size = get_cache_size(cache_dir)
        file_count = get_cache_file_count(cache_dir)
        total_size += size
        total_files += file_count
        
        if size > 0 or file_count > 0:
            print(f"  {cache_dir}:")
            print(f"    å¤§å°: {format_size(size)}")
            print(f"    æ–‡ä»¶æ•°: {file_count}")
    
    print(f"\nğŸ“¦ æ€»ç¼“å­˜ç»Ÿè®¡:")
    print(f"  æ€»å¤§å°: {format_size(total_size)}")
    print(f"  æ€»æ–‡ä»¶æ•°: {total_files}")


def analyze_cache_performance():
    """åˆ†æç¼“å­˜æ€§èƒ½"""
    print("\nğŸ” ç¼“å­˜æ€§èƒ½åˆ†æ")
    print("=" * 50)
    
    try:
        # åˆ†ææœ¬åœ°æ–‡ä»¶ç¼“å­˜æ€§èƒ½
        local_client = LocalFileStorageClient()
        local_stats = local_client.get_stats()
        
        print("\nğŸ’» æœ¬åœ°æ–‡ä»¶ç¼“å­˜æ€§èƒ½:")
        local_total_requests = local_stats.get('cache_hits', 0) + local_stats.get('cache_misses', 0)
        if local_total_requests > 0:
            local_hit_rate = local_stats.get('cache_hit_rate', 0)
            print(f"  ç¼“å­˜æ•ˆç‡: {'ä¼˜ç§€' if local_hit_rate > 0.8 else 'è‰¯å¥½' if local_hit_rate > 0.6 else 'éœ€è¦ä¼˜åŒ–'}")
            print(f"  å‘½ä¸­ç‡: {local_hit_rate:.2%}")
            print(f"  æ€»è¯·æ±‚: {local_total_requests}")
            
            if local_hit_rate < 0.6:
                print("  ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                print("    - æ–‡ä»¶å¯èƒ½é¢‘ç¹å˜æ›´ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡")
                print("    - è€ƒè™‘è°ƒæ•´ç¼“å­˜è¿‡æœŸæ—¶é—´")
                print("    - æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ¨¡å¼")
        else:
            print("  ğŸ“Š æš‚æ— è¶³å¤Ÿæ•°æ®è¿›è¡Œåˆ†æ")
            
    except Exception as e:
        logger.error(f"åˆ†æç¼“å­˜æ€§èƒ½å¤±è´¥: {e}")


def get_cache_info(file_path: Optional[str] = None):
    """è·å–ç‰¹å®šæ–‡ä»¶çš„ç¼“å­˜ä¿¡æ¯"""
    print("\nğŸ” æ–‡ä»¶ç¼“å­˜ä¿¡æ¯æŸ¥è¯¢")
    print("=" * 50)
    
    if file_path:
        print(f"\nğŸ’» æœ¬åœ°æ–‡ä»¶: {file_path}")
        try:
            local_client = LocalFileStorageClient()
            cache_info = local_client.get_cache_info(file_path)
            
            if cache_info:
                print(f"  æ–‡ä»¶è·¯å¾„: {cache_info['file_path']}")
                print(f"  ç¼“å­˜é”®: {cache_info['cache_key']}")
                print(f"  æ˜¯å¦ç¼“å­˜: {'æ˜¯' if cache_info['cached'] else 'å¦'}")
                print(f"  æ–‡ä»¶å¤§å°: {format_size(cache_info['file_size'])}")
                print(f"  ä¿®æ”¹æ—¶é—´: {cache_info['file_mtime']}")
                if cache_info['cached']:
                    print(f"  ç¼“å­˜å¤§å°: {format_size(cache_info['cache_size'])}")
            else:
                print("  âŒ æ— æ³•è·å–æ–‡ä»¶ç¼“å­˜ä¿¡æ¯ï¼ˆæ–‡ä»¶å¯èƒ½ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®ï¼‰")
                
        except Exception as e:
            logger.error(f"è·å–æœ¬åœ°æ–‡ä»¶ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")
            print(f"  âŒ è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")
    else:
        print("è¯·æŒ‡å®šè¦æŸ¥è¯¢çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„")


def export_cache_stats(output_file: str):
    """å¯¼å‡ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯åˆ°JSONæ–‡ä»¶"""
    try:
        stats_data = {
            "timestamp": str(Path().cwd()),
            "local_cache": {},
            "parsed_cache": {},
            "directory_stats": {}
        }
        
        # æ”¶é›†æœ¬åœ°æ–‡ä»¶ç¼“å­˜ç»Ÿè®¡
        try:
            local_client = LocalFileStorageClient()
            stats_data["local_cache"] = local_client.get_stats()
        except Exception as e:
            stats_data["local_cache"]["error"] = str(e)
        
        # æ”¶é›†è§£æç»“æœç¼“å­˜ç»Ÿè®¡
        try:
            parsed_cache = get_parsed_cache()
            stats_data["parsed_cache"] = parsed_cache.get_cache_stats()
        except Exception as e:
            stats_data["parsed_cache"]["error"] = str(e)
        
        # æ”¶é›†ç›®å½•ç¼“å­˜ç»Ÿè®¡
        cache_directories = [
            "cache/parsed_content",    # è§£æç»“æœç¼“å­˜
            "cache/document_images",   # å›¾åƒç¼“å­˜
            "cache/archive_files",     # å‹ç¼©æ–‡ä»¶ç¼“å­˜
            "cache",                   # æ€»ç¼“å­˜ç›®å½•
            "__pycache__"              # Pythonç¼“å­˜
        ]
        
        for cache_dir in cache_directories:
            stats_data["directory_stats"][cache_dir] = {
                "size_bytes": get_cache_size(cache_dir),
                "file_count": get_cache_file_count(cache_dir),
                "size_formatted": format_size(get_cache_size(cache_dir))
            }
        
        # å†™å…¥JSONæ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(stats_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯å·²å¯¼å‡ºåˆ°: {output_file}")
        return True
        
    except Exception as e:
        logger.error(f"å¯¼å‡ºç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return False


def perform_clear_operation(args):
    """æ‰§è¡Œæ¸…ç†æ“ä½œ"""
    if not confirm_clear_action():
        return
    
    success_count = 0
    total_count = 0
    
    if args.all or args.local:
        # æ¸…ç†æœ¬åœ°æ–‡ä»¶ç¼“å­˜
        print("\nğŸ—‘ï¸  æ¸…ç†æœ¬åœ°æ–‡ä»¶å­˜å‚¨ç¼“å­˜...")
        total_count += 1
        if clear_local_storage_cache():
            success_count += 1
    
    
    if args.all or args.parsed:
        # æ¸…ç†è§£æç»“æœç¼“å­˜
        print("\nğŸ—‘ï¸  æ¸…ç†è§£æç»“æœç¼“å­˜...")
        total_count += 1
        if clear_parsed_content_cache():
            success_count += 1
    
    if args.all:
        # æ¸…ç†æ‰€æœ‰ç¼“å­˜ç›®å½•
        print("\nğŸ—‘ï¸  æ¸…ç†æ‰€æœ‰ç¼“å­˜ç›®å½•...")
        cache_directories = [
            "cache",
            "__pycache__",
            "src/file_reader/__pycache__",
            "src/file_reader/parsers/__pycache__"
        ]
        for cache_dir in cache_directories:
            total_count += 1
            if clear_directory_cache(cache_dir):
                success_count += 1
    
    if args.dir:
        # æ¸…ç†æŒ‡å®šç›®å½•
        print(f"\nğŸ—‘ï¸  æ¸…ç†æŒ‡å®šç›®å½•: {args.dir}")
        total_count += 1
        if clear_directory_cache(args.dir):
            success_count += 1
    
    print(f"\nâœ… æ¸…ç†å®Œæˆ: {success_count}/{total_count} æˆåŠŸ")
    
    # æ¸…ç†åæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if success_count > 0:
        print("\nğŸ“Š æ¸…ç†åçš„ç¼“å­˜çŠ¶æ€:")
        show_cache_stats()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="MCP-Local-Reader ç¼“å­˜ç®¡ç†å·¥å…·")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯")
    parser.add_argument("--analyze", action="store_true", help="åˆ†æç¼“å­˜æ€§èƒ½")
    parser.add_argument("--clear", action="store_true", help="è¿›å…¥ç¼“å­˜æ¸…ç†æ¨¡å¼ï¼ˆéœ€è¦ç¡®è®¤ï¼‰")
    parser.add_argument("--info", action="store_true", help="æŸ¥è¯¢ç‰¹å®šæ–‡ä»¶çš„ç¼“å­˜ä¿¡æ¯")
    parser.add_argument("--export", type=str, help="å¯¼å‡ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯åˆ°JSONæ–‡ä»¶")
    
    # æ¸…ç†é€‰é¡¹ï¼ˆä»…åœ¨--clearæ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼‰
    parser.add_argument("--all", action="store_true", help="æ¸…ç†æ‰€æœ‰ç¼“å­˜ï¼ˆéœ€è¦--clearï¼‰")
    parser.add_argument("--local", action="store_true", help="æ¸…ç†æœ¬åœ°æ–‡ä»¶ç¼“å­˜ï¼ˆéœ€è¦--clearï¼‰")
    parser.add_argument("--parsed", action="store_true", help="æ¸…ç†è§£æç»“æœç¼“å­˜ï¼ˆéœ€è¦--clearï¼‰")
    parser.add_argument("--dir", type=str, help="æ¸…ç†æŒ‡å®šç›®å½•ï¼ˆéœ€è¦--clearï¼‰")
    
    # æŸ¥è¯¢é€‰é¡¹ï¼ˆä»…åœ¨--infoæ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼‰
    parser.add_argument("--file", type=str, help="æŸ¥è¯¢æœ¬åœ°æ–‡ä»¶çš„ç¼“å­˜ä¿¡æ¯ï¼ˆéœ€è¦--infoï¼‰")
    
    args = parser.parse_args()
    
    print("ğŸ› ï¸  MCP-Local-Reader ç¼“å­˜ç®¡ç†å·¥å…·")
    print("=" * 50)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    if args.stats:
        show_cache_stats()
        return
    
    # åˆ†æç¼“å­˜æ€§èƒ½
    if args.analyze:
        show_cache_stats()
        analyze_cache_performance()
        return
    
    # æŸ¥è¯¢æ–‡ä»¶ç¼“å­˜ä¿¡æ¯
    if args.info:
        if not args.file:
            print("âŒ é”™è¯¯: ä½¿ç”¨ --info å‚æ•°æ—¶ï¼Œéœ€è¦æŒ‡å®š --file")
            print("\nä½¿ç”¨ç¤ºä¾‹:")
            print("  python cache_utils.py --info --file /path/to/file.txt")
            return
        
        get_cache_info(file_path=args.file)
        return
    
    # å¯¼å‡ºç¼“å­˜ç»Ÿè®¡
    if args.export:
        export_cache_stats(args.export)
        return
    
    # è¿›å…¥æ¸…ç†æ¨¡å¼
    if args.clear:
        # æ£€æŸ¥æ˜¯å¦æœ‰å…·ä½“çš„æ¸…ç†é€‰é¡¹
        if not any([args.all, args.local, args.parsed, args.dir]):
            print("âŒ é”™è¯¯: ä½¿ç”¨ --clear å‚æ•°æ—¶ï¼Œéœ€è¦æŒ‡å®šå…·ä½“çš„æ¸…ç†é€‰é¡¹")
            print("\nå¯ç”¨çš„æ¸…ç†é€‰é¡¹:")
            print("  --all      æ¸…ç†æ‰€æœ‰ç¼“å­˜")
            print("  --local    æ¸…ç†æœ¬åœ°æ–‡ä»¶ç¼“å­˜")
            print("  --parsed   æ¸…ç†è§£æç»“æœç¼“å­˜")
            print("  --dir DIR  æ¸…ç†æŒ‡å®šç›®å½•")
            return
        
        perform_clear_operation(args)
        return
    
    # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©å’Œç»Ÿè®¡ä¿¡æ¯
    if not any([args.stats, args.analyze, args.clear, args.info, args.export]):
        show_cache_stats()
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("  python cache_utils.py --stats                      # æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡")
        print("  python cache_utils.py --analyze                    # åˆ†æç¼“å­˜æ€§èƒ½")
        print("  python cache_utils.py --info --file /path/to/file  # æŸ¥è¯¢æ–‡ä»¶ç¼“å­˜ä¿¡æ¯")
        print("  python cache_utils.py --export stats.json         # å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯")
        print("  python cache_utils.py --clear --all               # æ¸…ç†æ‰€æœ‰ç¼“å­˜")
        print("  python cache_utils.py --clear --local             # æ¸…ç†æœ¬åœ°ç¼“å­˜")


if __name__ == "__main__":
    main() 