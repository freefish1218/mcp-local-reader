#!/usr/bin/env python3
"""
MCPæ–‡ä»¶è¯»å–å™¨å®¢æˆ·ç«¯ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨MCPæ–‡ä»¶è¯»å–å™¨æœåŠ¡ï¼Œæ”¯æŒHTTPä¸‹è½½ã€æœ¬åœ°æ–‡ä»¶è¯»å–å’Œæ™ºèƒ½ä¸Šä¼ 
"""

import asyncio
import json
import argparse
from typing import List, Tuple, Dict
from pathlib import Path

from fastmcp import Client
from fastmcp.client.transports import StreamableHttpTransport


class MCPFileReaderClient:
    """MCPæ–‡ä»¶è¯»å–å™¨å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = "http://localhost:3001/mcp"):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            base_url: MCPæœåŠ¡å™¨åŸºç¡€URL
        """
        self.base_url = base_url.rstrip('/')
        self.transport = StreamableHttpTransport(self.base_url)
        self.client = Client(self.transport)
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.client.__aenter__()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        await self.client.__aexit__(exc_type, exc_val, exc_tb)
    

    
    async def read_local_files(
        self, 
        file_paths: List[str], 
        max_size: int = None  # MBå•ä½ï¼Œä¸ºç©ºæ—¶ä½¿ç”¨æœåŠ¡å™¨ç«¯ç¯å¢ƒå˜é‡FILE_READER_MAX_FILE_SIZE_MBçš„é»˜è®¤å€¼
    ) -> dict:
        """
        ä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè¯»å–æ–‡ä»¶å†…å®¹ï¼ˆä»…æ”¯æŒç»å¯¹è·¯å¾„ï¼‰
        
        Args:
            file_paths: æœ¬åœ°æ–‡ä»¶ç»å¯¹è·¯å¾„åˆ—è¡¨ï¼Œå¿…é¡»ä½¿ç”¨å®Œæ•´çš„ç»å¯¹è·¯å¾„
            max_size: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œä¸ºç©ºæ—¶ä½¿ç”¨æœåŠ¡å™¨ç«¯ç¯å¢ƒå˜é‡é…ç½®
            
        Returns:
            è¯»å–ç»“æœå­—å…¸
        """
        kwargs = {
            "file_paths": file_paths
        }
        if max_size is not None:
            kwargs["max_size"] = max_size
        
        result = await self.client.call_tool("read_local_files", kwargs)
        
        # è§£æè¿”å›çš„å†…å®¹
        if result and len(result) > 0 and hasattr(result[0], 'text'):
            return json.loads(result[0].text)
        
        return {"contents": [], "failed": []}
    
    async def upload_and_read_files(
        self,
        file_paths: List[str],
        max_size: int = None,
        cleanup_after: bool = True
    ) -> dict:
        """
        ä¸Šä¼ æ–‡ä»¶å¹¶è¯»å–å†…å®¹ï¼ˆé€‚ç”¨äºDockerç¯å¢ƒï¼‰
        
        Args:
            file_paths: æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            max_size: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œä¸ºç©ºæ—¶ä½¿ç”¨æœåŠ¡å™¨ç«¯ç¯å¢ƒå˜é‡é…ç½®
            cleanup_after: å¤„ç†å®Œæˆåæ˜¯å¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            
        Returns:
            è¯»å–ç»“æœå­—å…¸
        """
        import base64
        
        # å‡†å¤‡ç»“æœå®¹å™¨
        all_contents = []
        all_failed = []
        
        for file_path in file_paths:
            try:
                file_path_obj = Path(file_path)
                if not file_path_obj.exists():
                    print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    all_failed.append({
                        "resource_id": file_path_obj.name,
                        "type": "file_not_found",
                        "error_message": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                    })
                    continue
                
                # è¯»å–æ–‡ä»¶å¹¶ç¼–ç 
                with open(file_path, 'rb') as f:
                    content = base64.b64encode(f.read()).decode()
                    print(f"ğŸ“¤ å·²å‡†å¤‡ä¸Šä¼ æ–‡ä»¶: {file_path_obj.name}")
                
                # è°ƒç”¨å•æ–‡ä»¶ä¸Šä¼ API
                kwargs = {
                    "filename": file_path_obj.name,
                    "content": content,
                    "cleanup_after": cleanup_after
                }
                if max_size is not None:
                    kwargs["max_size"] = max_size
                
                result = await self.client.call_tool("upload_and_read_file", kwargs)
                
                # è§£æå•ä¸ªæ–‡ä»¶çš„ç»“æœ
                if result and len(result) > 0 and hasattr(result[0], 'text'):
                    single_result = json.loads(result[0].text)
                    
                    # åˆå¹¶ç»“æœ
                    all_contents.extend(single_result.get('contents', []))
                    all_failed.extend(single_result.get('failed', []))
                else:
                    all_failed.append({
                        "resource_id": file_path_obj.name,
                        "type": "api_error",
                        "error_message": "APIè°ƒç”¨è¿”å›ç©ºç»“æœ"
                    })
                    
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path}, é”™è¯¯: {e}")
                all_failed.append({
                    "resource_id": Path(file_path).name,
                    "type": "processing_error", 
                    "error_message": str(e)
                })
                continue
        
        return {
            "contents": all_contents,
            "failed": all_failed
        }
    
    async def read_files_smart(
        self, 
        file_paths: List[str],
        max_size: int = None,
        **kwargs
    ) -> dict:
        """
        æ™ºèƒ½æ–‡ä»¶è¯»å– - è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ–¹æ³•
        
        å…ˆå°è¯•æœ¬åœ°æ–‡ä»¶è¯»å–ï¼Œå¦‚æœå¤±è´¥åˆ™è‡ªåŠ¨åˆ‡æ¢åˆ°æ–‡ä»¶ä¸Šä¼ æ¨¡å¼
        
        Args:
            file_paths: æœ¬åœ°æ–‡ä»¶ç»å¯¹è·¯å¾„åˆ—è¡¨
            max_size: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            è¯»å–ç»“æœå­—å…¸
        """
        print(f"ğŸ” æ™ºèƒ½æ–‡ä»¶è¯»å–æ¨¡å¼ - å¤„ç† {len(file_paths)} ä¸ªæ–‡ä»¶")
        
        try:
            # å…ˆå°è¯•æœ¬åœ°æ–‡ä»¶è¯»å–
            print("ğŸ”§ å°è¯•æœ¬åœ°æ–‡ä»¶è¯»å–æ¨¡å¼...")
            result = await self.read_local_files(
                file_paths, 
                max_size=max_size
            )
            print("âœ… æœ¬åœ°æ–‡ä»¶è¯»å–æˆåŠŸ")
            return result
            
        except Exception as e:
            error_msg = str(e).lower()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·ä¸å¯ç”¨çš„é”™è¯¯
            if any(keyword in error_msg for keyword in [
                "read_local_files", 
                "tool not found", 
                "unknown tool",
                "docker",
                "container"
            ]):
                print("ğŸ³ æ£€æµ‹åˆ°Dockerç¯å¢ƒæˆ–æœ¬åœ°è¯»å–ä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°æ–‡ä»¶ä¸Šä¼ æ¨¡å¼...")
                
                try:
                    result = await self.upload_and_read_files(
                        file_paths,
                        max_size=max_size,
                        cleanup_after=kwargs.get('cleanup_after', True)
                    )
                    print("âœ… æ–‡ä»¶ä¸Šä¼ è¯»å–æˆåŠŸ")
                    return result
                    
                except Exception as upload_error:
                    print(f"âŒ æ–‡ä»¶ä¸Šä¼ è¯»å–ä¹Ÿå¤±è´¥: {upload_error}")
                    raise upload_error
            else:
                # å…¶ä»–ç±»å‹çš„é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                print(f"âŒ æœ¬åœ°æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                raise e
    
    async def get_server_info(self) -> dict:
        """
        è·å–æœåŠ¡å™¨ä¿¡æ¯
        """
        result = await self.client.call_tool("get_server_info", {})
        return json.loads(result[0].text)

    async def get_reader_stats(self) -> dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        result = await self.client.call_tool("get_reader_stats", {})
        
        if result and len(result) > 0 and hasattr(result[0], 'text'):
            return json.loads(result[0].text)
        
        return {}
    
    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯è¿æ¥"""
        if hasattr(self.client, 'close'):
            await self.client.close()

    async def read_files(
        self, 
        urls: List[Dict[str, str]], 
        default_referer: str = None,
        expires: int = None,
        max_size: int = None,  # MBå•ä½ï¼Œä¸ºç©ºæ—¶ä½¿ç”¨æœåŠ¡å™¨ç«¯ç¯å¢ƒå˜é‡FILE_READER_MAX_FILE_SIZE_MBçš„é»˜è®¤å€¼
        use_proxy: bool = False,
        max_retries: int = 3,
        max_workers: int = 3
    ) -> dict:
        """
        é€šè¿‡HTTPä¸‹è½½é“¾æ¥è¯»å–æ–‡ä»¶å†…å®¹
        
        Args:
            urls: æ–‡ä»¶ä¸‹è½½é“¾æ¥æ•°ç»„ï¼Œæ ¼å¼: [{"url": "url1", "referer": "ref1"}, {"url": "url2"}]
            default_referer: é»˜è®¤Refererï¼Œåº”ç”¨äºæ‰€æœ‰æœªæŒ‡å®šä¸“å±Refererçš„é“¾æ¥
            expires: æ–‡ä»¶è¿‡æœŸæ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºä¸‹è½½æœåŠ¡çš„ç¼“å­˜ç®¡ç†
            max_size: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œä¸ºç©ºæ—¶ä½¿ç”¨æœåŠ¡å™¨ç«¯ç¯å¢ƒå˜é‡é…ç½®
            use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†ä¸‹è½½æ–‡ä»¶
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            max_workers: æœ€å¤§å¹¶å‘å·¥ä½œçº¿ç¨‹æ•°
            
        Returns:
            è¯»å–ç»“æœå­—å…¸
        """
        kwargs = {
            "urls": urls,
            "use_proxy": use_proxy,
            "max_retries": max_retries,
            "max_workers": max_workers
        }
        if default_referer:
            kwargs["default_referer"] = default_referer
        if expires is not None:
            kwargs["expires"] = expires
        if max_size is not None:
            kwargs["max_size"] = max_size
            
        result = await self.client.call_tool("read_files", kwargs)
        
        # è§£æè¿”å›çš„å†…å®¹
        if result and len(result) > 0 and hasattr(result[0], 'text'):
            return json.loads(result[0].text)
        
        return {"contents": [], "failed": []}


def print_file_results(result: dict, file_type: str = "æ–‡ä»¶", detailed: bool = False):
    """
    æ‰“å°æ–‡ä»¶è¯»å–ç»“æœ
    
    Args:
        result: è¯»å–ç»“æœå­—å…¸
        file_type: æ–‡ä»¶ç±»å‹æè¿°
        detailed: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†å†…å®¹
    """
    success_count = len(result.get('contents', []))
    failed_count = len(result.get('failed', []))
    total_count = success_count + failed_count
    
    print(f"   ğŸ“Š è¯»å–ç»“æœç»Ÿè®¡:")
    print(f"   æ€»è®¡{file_type}æ•°: {total_count}")
    print(f"   æˆåŠŸ{file_type}æ•°: {success_count}")
    print(f"   å¤±è´¥{file_type}æ•°: {failed_count}")
    if total_count > 0:
        success_rate = (success_count / total_count) * 100
        print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
    
    # æ˜¾ç¤ºæˆåŠŸè¯»å–çš„å†…å®¹
    for i, content in enumerate(result.get('contents', []), 1):
        resource_id = content.get('resource_id', '')
        text_content = content.get('content', '')
        file_extension = Path(resource_id).suffix.lower()
        print(f"\n   âœ… [{i}] {resource_id} ({file_extension})")
        print(f"      å†…å®¹é•¿åº¦: {len(text_content):,} å­—ç¬¦")
        
        if detailed and text_content:
            # è¯¦ç»†æ¨¡å¼æ˜¾ç¤ºæ›´å¤šå†…å®¹
            if len(text_content) > 500:
                preview = text_content[:500] + "..."
            else:
                preview = text_content
            print(f"      å†…å®¹é¢„è§ˆ: {preview}")
        elif text_content:
            # ç®€è¦æ¨¡å¼åªæ˜¾ç¤ºå¼€å¤´
            if len(text_content) > 100:
                preview = text_content[:100] + "..."
            else:
                preview = text_content
            print(f"      å†…å®¹é¢„è§ˆ: {preview}")
    
    # æ˜¾ç¤ºå¤±è´¥çš„æ–‡ä»¶
    for i, failed in enumerate(result.get('failed', []), 1):
        resource_id = failed.get('resource_id', '')
        failure_type = failed.get('type', '')
        error_message = failed.get('error_message', '')
        file_extension = Path(resource_id).suffix.lower()
        print(f"\n   âŒ [{i}] {resource_id} ({file_extension})")
        print(f"      å¤±è´¥ç±»å‹: {failure_type}")
        print(f"      é”™è¯¯ä¿¡æ¯: {error_message}")


def get_all_test_files() -> List[Tuple[str, str]]:
    """
    è·å– tests/files ç›®å½•ä¸‹çš„æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
    
    Returns:
        åŒ…å«æ–‡ä»¶è·¯å¾„å’Œæè¿°çš„å…ƒç»„åˆ—è¡¨
    """
    test_files_dir = Path("tests/files")
    test_files = []
    
    if not test_files_dir.exists():
        return test_files
    
    # æ–‡ä»¶æ‰©å±•ååˆ°æè¿°çš„æ˜ å°„
    extension_descriptions = {
        '.pdf': 'PDFæ–‡æ¡£',
        '.doc': 'Wordæ–‡æ¡£(æ—§æ ¼å¼)',
        '.docx': 'Wordæ–‡æ¡£',
        '.xls': 'Excelè¡¨æ ¼(æ—§æ ¼å¼)',
        '.xlsx': 'Excelè¡¨æ ¼',
        '.ppt': 'PowerPointæ¼”ç¤º(æ—§æ ¼å¼)',
        '.pptx': 'PowerPointæ¼”ç¤º',
        '.odt': 'OpenDocumentæ–‡æœ¬',
        '.ods': 'OpenDocumentè¡¨æ ¼',
        '.odp': 'OpenDocumentæ¼”ç¤º',
        '.txt': 'çº¯æ–‡æœ¬æ–‡ä»¶',
        '.rtf': 'RTFæ–‡æ¡£',
        '.md': 'Markdownæ–‡æ¡£',
        '.markdown': 'Markdownæ–‡æ¡£',
        '.jpg': 'JPEGå›¾ç‰‡',
        '.jpeg': 'JPEGå›¾ç‰‡',
        '.png': 'PNGå›¾ç‰‡',
        '.gif': 'GIFå›¾ç‰‡',
        '.bmp': 'BMPå›¾ç‰‡',
        '.webp': 'WebPå›¾ç‰‡',
        '.tiff': 'TIFFå›¾ç‰‡',
    }
    
    # éå†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for file_path in sorted(test_files_dir.iterdir()):
        if file_path.is_file():
            extension = file_path.suffix.lower()
            description = extension_descriptions.get(extension, f'{extension}æ–‡ä»¶')
            # ä½¿ç”¨ç»å¯¹è·¯å¾„
            absolute_path = str(file_path.resolve())
            test_files.append((absolute_path, description))
    
    return test_files


async def test_all_files(client: MCPFileReaderClient, detailed: bool = False):
    """å…¨é¢æµ‹è¯• tests/files ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶"""
    print("\nğŸ§ª å…¨é¢æ–‡ä»¶æµ‹è¯•æ¨¡å¼")
    print("=" * 50)
    
    test_files = get_all_test_files()
    
    if not test_files:
        print("âŒ æœªæ‰¾åˆ° tests/files ç›®å½•æˆ–ç›®å½•ä¸ºç©º")
        print("   è¯·ç¡®ä¿å­˜åœ¨ tests/files ç›®å½•å¹¶åŒ…å«æµ‹è¯•æ–‡ä»¶")
        return
    
    print(f"ğŸ“‚ å‘ç° {len(test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶:")
    
    # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„æ˜¾ç¤º
    file_types = {}
    for file_path, description in test_files:
        extension = Path(file_path).suffix.lower()
        if extension not in file_types:
            file_types[extension] = []
        file_types[extension].append((file_path, description))
    
    for extension, files in sorted(file_types.items()):
        print(f"   {extension}: {len(files)} ä¸ªæ–‡ä»¶")
        for file_path, description in files:
            print(f"     ğŸ“„ {Path(file_path).name} - {description}")
    
    print(f"\nğŸš€ å¼€å§‹æµ‹è¯•æ‰€æœ‰æ–‡ä»¶...")
    
    # æå–æ–‡ä»¶è·¯å¾„
    file_paths = [file_path for file_path, _ in test_files]
    
    # æ‰¹é‡å¤„ç†ï¼šæ¯æ¬¡æœ€å¤šå¤„ç†10ä¸ªæ–‡ä»¶ï¼ˆæœåŠ¡å™¨é™åˆ¶ï¼‰
    batch_size = 10
    all_contents = []
    all_failed = []
    
    try:
        total_batches = (len(file_paths) + batch_size - 1) // batch_size
        print(f"   ğŸ“¦ å°†åˆ† {total_batches} æ‰¹å¤„ç†ï¼Œæ¯æ‰¹æœ€å¤š {batch_size} ä¸ªæ–‡ä»¶")
        
        for i in range(0, len(file_paths), batch_size):
            batch_files = file_paths[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            print(f"\n   ğŸ”„ å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch_files)} ä¸ªæ–‡ä»¶)...")
            for j, file_path in enumerate(batch_files, 1):
                print(f"     [{j}] {Path(file_path).name}")
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡
            batch_result = await client.read_local_files(
                batch_files, 
                max_size=50, # æœ¬åœ°è¯»å–æ–‡ä»¶å¤§å°é™åˆ¶ä¸º50MB
            )
            
            # åˆå¹¶ç»“æœ
            batch_contents = batch_result.get('contents', [])
            batch_failed = batch_result.get('failed', [])
            all_contents.extend(batch_contents)
            all_failed.extend(batch_failed)
            
            print(f"     âœ… ç¬¬ {batch_num} æ‰¹å®Œæˆ: æˆåŠŸ {len(batch_contents)}, å¤±è´¥ {len(batch_failed)}")
        
        # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
        result = {
            'contents': all_contents,
            'failed': all_failed
        }
        
        print(f"\nğŸ“Š æ€»ä½“æµ‹è¯•ç»“æœ:")
        print_file_results(result, "æµ‹è¯•æ–‡ä»¶", detailed=detailed)
        
        # æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡ç»“æœ
        print(f"\nğŸ“ˆ æŒ‰æ–‡ä»¶ç±»å‹ç»Ÿè®¡:")
        success_by_type = {}
        failed_by_type = {}
        
        # ç»Ÿè®¡æˆåŠŸçš„æ–‡ä»¶
        for content in result.get('contents', []):
            resource_id = content.get('resource_id', '')
            extension = Path(resource_id).suffix.lower()
            success_by_type[extension] = success_by_type.get(extension, 0) + 1
        
        # ç»Ÿè®¡å¤±è´¥çš„æ–‡ä»¶
        for failed in result.get('failed', []):
            resource_id = failed.get('resource_id', '')
            extension = Path(resource_id).suffix.lower()
            failed_by_type[extension] = failed_by_type.get(extension, 0) + 1
        
        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
        all_extensions = set(success_by_type.keys()) | set(failed_by_type.keys())
        for extension in sorted(all_extensions):
            success = success_by_type.get(extension, 0)
            failed = failed_by_type.get(extension, 0)
            total = success + failed
            success_rate = (success / total * 100) if total > 0 else 0
            print(f"   {extension}: {success}/{total} æˆåŠŸ ({success_rate:.1f}%)")
        
    except Exception as e:
        print(f"âŒ æ–‡ä»¶æµ‹è¯•å¤±è´¥: {e}")


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="MCPæ–‡ä»¶è¯»å–å™¨å®¢æˆ·ç«¯ç¤ºä¾‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  %(prog)s --local                     # æœ¬åœ°è¯»å–æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ï¼ˆä»…åŸç”Ÿç¯å¢ƒï¼‰
  %(prog)s --local file1.txt file2.pdf # æœ¬åœ°è¯»å–æŒ‡å®šæ–‡ä»¶ï¼ˆä»…åŸç”Ÿç¯å¢ƒï¼‰
  %(prog)s --smart                     # æ™ºèƒ½è¯»å–æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ï¼ˆæ¨èï¼‰
  %(prog)s --smart file1.txt file2.pdf # æ™ºèƒ½è¯»å–æŒ‡å®šæ–‡ä»¶ï¼ˆæ¨èï¼‰
  %(prog)s --http                      # HTTPä¸‹è½½è¯»å–ç¤ºä¾‹æ–‡ä»¶
  %(prog)s --http url1 url2            # HTTPä¸‹è½½è¯»å–æŒ‡å®šURL
  %(prog)s --port 3002 --smart         # æŒ‡å®šç«¯å£å¹¶æ™ºèƒ½è¯»å–
  
æ™ºèƒ½æ¨¡å¼è¯´æ˜:
  --smart æ¨¡å¼ä¼šè‡ªåŠ¨æ£€æµ‹æœåŠ¡å™¨ç¯å¢ƒï¼š
  â€¢ åŸç”Ÿç¯å¢ƒ: ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è¯»å–
  â€¢ Dockerç¯å¢ƒ: è‡ªåŠ¨ä¸Šä¼ æ–‡ä»¶å¹¶è¯»å–
        """
    )
    
    parser.add_argument(
        '--port', '-p',
        type=int,
        default=3001,
        help='MCPæœåŠ¡å™¨ç«¯å£å· (é»˜è®¤: 3001)'
    )
    
    parser.add_argument(
        '--local',
        nargs='*',
        help='æœ¬åœ°æ–‡ä»¶æ¨¡å¼ï¼ˆå¯æŒ‡å®šæ–‡ä»¶è·¯å¾„ï¼Œä¸æŒ‡å®šåˆ™è¯»å–æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ï¼‰'
    )
    
    parser.add_argument(
        '--smart',
        nargs='*',
        help='æ™ºèƒ½æ–‡ä»¶è¯»å–æ¨¡å¼ï¼ˆè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå¹¶é€‰æ‹©æœ€ä½³æ–¹æ³•ï¼‰'
    )
    
    parser.add_argument(
        '--http',
        nargs='*',
        help='HTTPä¸‹è½½æ¨¡å¼ï¼ˆå¯æŒ‡å®šURLåˆ—è¡¨ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨ç¤ºä¾‹URLï¼‰'
    )
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°ï¼šå¿…é¡»æŒ‡å®š --localã€--http æˆ– --smart ä¸­çš„ä¸€ä¸ª
    specified_modes = sum([
        args.local is not None,
        args.http is not None, 
        args.smart is not None
    ])
    
    if specified_modes == 0:
        parser.error("å¿…é¡»æŒ‡å®š --localã€--http æˆ– --smart ä¸­çš„ä¸€ä¸ª")
    
    if specified_modes > 1:
        parser.error("ä¸èƒ½åŒæ—¶æŒ‡å®šå¤šä¸ªè¯»å–æ¨¡å¼")
    
    return args


async def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # æ„å»ºæœåŠ¡å™¨URL
    base_url = f"http://localhost:{args.port}/mcp"
    
    # åˆ›å»ºå®¢æˆ·ç«¯å¹¶ä½¿ç”¨context manager
    async with MCPFileReaderClient(base_url) as client:
        try:
            print("ğŸ” MCPæ–‡ä»¶è¯»å–å™¨å®¢æˆ·ç«¯ç¤ºä¾‹")
            print("=" * 50)
            print(f"ğŸŒ æœåŠ¡å™¨åœ°å€: {base_url}")
                        
            # ç¯å¢ƒè¯´æ˜
            print("\n2.1. ç¯å¢ƒè¯´æ˜...")
            print("   ğŸ’¡ ä½¿ç”¨å»ºè®®:")
            print("     â€¢ æ¨èä½¿ç”¨ --smart æ¨¡å¼è¿›è¡Œæ™ºèƒ½è¯»å–")
            print("     â€¢ æœåŠ¡å™¨ä¼šè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå¹¶é€‰æ‹©æœ€ä½³æ–¹æ³•")
            print("     â€¢ åŸç”Ÿç¯å¢ƒ: æœ¬åœ°æ–‡ä»¶ç›´æ¥è¯»å–")
            print("     â€¢ Dockerç¯å¢ƒ: æ–‡ä»¶ä¸Šä¼ å¤„ç†")
            
            # æ ¹æ®å‚æ•°æ‰§è¡Œæ“ä½œ
            if args.local is not None:
                # æœ¬åœ°æ–‡ä»¶æ¨¡å¼
                if args.local:
                    # æŒ‡å®šäº†æ–‡ä»¶è·¯å¾„
                    print(f"\n3. è¯»å–æŒ‡å®šæœ¬åœ°æ–‡ä»¶...")
                    print(f"   æ–‡ä»¶è·¯å¾„: {args.local}")
                    result = await client.read_local_files(args.local)
                    print_file_results(result, "æœ¬åœ°æ–‡ä»¶", detailed=True)
                else:
                    # è¯»å–æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
                    print(f"\n3. è¯»å–æ‰€æœ‰æœ¬åœ°æµ‹è¯•æ–‡ä»¶...")
                    await test_all_files(client, detailed=True)
            
            elif args.smart is not None:
                # æ™ºèƒ½æ–‡ä»¶è¯»å–æ¨¡å¼
                if args.smart:
                    # æŒ‡å®šäº†æ–‡ä»¶è·¯å¾„
                    print(f"\n3. æ™ºèƒ½è¯»å–æŒ‡å®šæ–‡ä»¶...")
                    print(f"   æ–‡ä»¶è·¯å¾„: {args.smart}")
                    result = await client.read_files_smart(args.smart)
                    print_file_results(result, "æ™ºèƒ½è¯»å–", detailed=True)
                else:
                    # æ™ºèƒ½è¯»å–æµ‹è¯•æ–‡ä»¶ï¼ˆDockerç¯å¢ƒä¸‹é™åˆ¶æ•°é‡ï¼‰
                    print(f"\n3. æ™ºèƒ½è¯»å–æµ‹è¯•æ–‡ä»¶...")
                    test_files = get_all_test_files()
                    if test_files:
                        # ä¸ºäº†é¿å…Dockerç¯å¢ƒä¸‹æ–‡ä»¶ä¸Šä¼ è¿‡å¤šå¯¼è‡´è¶…æ—¶ï¼Œé™åˆ¶æ–‡ä»¶æ•°é‡å’Œå¤§å°
                        # é€‰æ‹©ä¸åŒç±»å‹çš„ä»£è¡¨æ€§å°æ–‡ä»¶è¿›è¡Œæµ‹è¯•
                        selected_files = []
                        file_types_seen = set()
                        
                        # æŒ‰æ–‡ä»¶å¤§å°æ’åºï¼Œä¼˜å…ˆé€‰æ‹©å°æ–‡ä»¶
                        test_files_with_size = []
                        for file_path, description in test_files:
                            try:
                                file_size = Path(file_path).stat().st_size
                                test_files_with_size.append((file_path, description, file_size))
                            except OSError:
                                # æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ï¼Œè·³è¿‡
                                continue
                        
                        # æŒ‰æ–‡ä»¶å¤§å°æ’åº
                        test_files_with_size.sort(key=lambda x: x[2])
                        
                        # ä¼˜å…ˆé€‰æ‹©ä¸åŒç±»å‹çš„å°æ–‡ä»¶ï¼ˆå°äº1MBï¼‰ï¼Œæœ€å¤š3ä¸ª
                        max_file_size = 1024 * 1024  # 1MB
                        for file_path, description, file_size in test_files_with_size:
                            extension = Path(file_path).suffix.lower()
                            if (extension not in file_types_seen and 
                                len(selected_files) < 3 and 
                                file_size < max_file_size):
                                selected_files.append(file_path)
                                file_types_seen.add(extension)
                        
                        # å¦‚æœå°æ–‡ä»¶ç±»å‹ä¸è¶³3ç§ï¼Œè¡¥å……å°æ–‡ä»¶åˆ°3ä¸ª
                        if len(selected_files) < 3:
                            for file_path, description, file_size in test_files_with_size:
                                if (file_path not in selected_files and 
                                    len(selected_files) < 3 and 
                                    file_size < max_file_size):
                                    selected_files.append(file_path)
                        
                        if selected_files:
                            print(f"   ğŸ“ ä¸ºé¿å…Dockerç¯å¢ƒä¸Šä¼ è¶…æ—¶ï¼Œé€‰æ‹© {len(selected_files)} ä¸ªå°æ–‡ä»¶(<1MB):")
                            for i, file_path in enumerate(selected_files, 1):
                                extension = Path(file_path).suffix.lower()
                                file_size = Path(file_path).stat().st_size
                                size_str = f"{file_size/1024:.1f}KB" if file_size < 1024*1024 else f"{file_size/(1024*1024):.1f}MB"
                                print(f"     [{i}] {Path(file_path).name} ({extension}, {size_str})")
                            
                            print(f"   ğŸ’¡ å¦‚éœ€æµ‹è¯•å¤§æ–‡ä»¶æˆ–æ‰€æœ‰æ–‡ä»¶ï¼Œè¯·å•ç‹¬æŒ‡å®šæ–‡ä»¶è·¯å¾„")
                            
                            result = await client.read_files_smart(selected_files)
                            print_file_results(result, "æ™ºèƒ½è¯»å–", detailed=True)
                        else:
                            print("   âŒ æœªæ‰¾åˆ°åˆé€‚çš„å°æ–‡ä»¶è¿›è¡Œæµ‹è¯•")
                    else:
                        print("   âŒ æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
            
            elif args.http is not None:
                # HTTPä¸‹è½½æ¨¡å¼
                if args.http:
                    # æŒ‡å®šäº†URL
                    print(f"\n3. è¯»å–æŒ‡å®šHTTPæ–‡ä»¶...")
                    print(f"   ä¸‹è½½é“¾æ¥: {args.http}")
                    
                    # è½¬æ¢ä¸ºæ–°çš„æ ¼å¼
                    urls_with_referer = [{"url": url} for url in args.http]
                    
                    result = await client.read_files(urls_with_referer)
                    print_file_results(result, "HTTPæ–‡ä»¶", detailed=True)
                else:
                    # ä½¿ç”¨ç¤ºä¾‹URLè¿›è¡Œæ¼”ç¤º
                    print(f"\n3. HTTPä¸‹è½½æ¼”ç¤º...")
                    
                    # æ¼”ç¤ºper-URL refereråŠŸèƒ½
                    urls_with_referer = [
                        {
                            "url": "https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf",
                            "referer": "https://www.w3.org"
                        },
                        {
                            "url": "https://file-examples.com/storage/fe086c9c8dae5b8c62d4a0e/2017/10/file_example_JPG_100kB.jpg"
                        }  # å›¾ç‰‡æ–‡ä»¶ä½¿ç”¨é»˜è®¤referer
                    ]
                    
                    print(f"   æ¼”ç¤ºé“¾æ¥: {[item['url'] for item in urls_with_referer]}")
                    print(f"   ğŸ’¡ æ³¨æ„: éœ€è¦ç¡®ä¿HTTPä¸‹è½½æœåŠ¡æ­£å¸¸è¿è¡Œä¸”èƒ½è®¿é—®è¿™äº›URL")
                    
                    try:
                        print(f"   ğŸ†• ä½¿ç”¨per-URL refereråŠŸèƒ½:")
                        print(f"     â€¢ PDFæ–‡ä»¶ä¸“å±referer: https://www.w3.org")
                        print(f"     â€¢ å›¾ç‰‡æ–‡ä»¶ä½¿ç”¨é»˜è®¤referer")
                        
                        result = await client.read_files(
                            urls_with_referer,
                            default_referer="https://www.example.com",  # é»˜è®¤referer
                            max_size=10,  # 10MBé™åˆ¶
                            use_proxy=False
                        )
                        print_file_results(result, "HTTPæ–‡ä»¶", detailed=True)
                    except Exception as e:
                        print(f"   âŒ HTTPä¸‹è½½æ¼”ç¤ºå¤±è´¥: {e}")
                        print(f"   ğŸ’¡ è¯·æ£€æŸ¥HTTPä¸‹è½½æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Œæˆ–ä½¿ç”¨å…¶ä»–å¯è®¿é—®çš„URL")
            
            print("\nâœ… ç¤ºä¾‹å®Œæˆ")
            
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 