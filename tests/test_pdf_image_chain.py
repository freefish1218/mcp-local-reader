#!/usr/bin/env python3
"""
PDFå›¾ç‰‡é“¾å¼å¤„ç†é›†æˆæµ‹è¯•
æµ‹è¯•å®Œæ•´æµç¨‹ï¼šPDFä¸Šä¼  â†’ è§£æMarkdown â†’ æå–å›¾ç‰‡é“¾æ¥ â†’ OCRè¯†åˆ«
"""

import asyncio
import json
import re
import sys
import time
from pathlib import Path

import httpx
from fastmcp import Client
from fastmcp.client.transports import StreamableHttpTransport


def extract_image_links(markdown_content: str) -> list:
    """
    ä»Markdownå†…å®¹ä¸­æå–å›¾ç‰‡é“¾æ¥
    
    Args:
        markdown_content: Markdownæ–‡æœ¬å†…å®¹
        
    Returns:
        å›¾ç‰‡é“¾æ¥åˆ—è¡¨ï¼ˆresource_idæ ¼å¼ï¼Œå»æ‰file://å‰ç¼€ï¼‰
    """
    # åŒ¹é…Markdownå›¾ç‰‡è¯­æ³•: ![alt](file:///resource_id)
    pattern = r'!\[.*?\]\(file:///([^)]+\.(?:png|jpg|jpeg|gif|bmp|webp|tiff))\)'
    matches = re.findall(pattern, markdown_content)
    return matches


def format_duration(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        remaining_seconds = seconds % 60
        return f"{minutes}åˆ†{remaining_seconds:.1f}ç§’"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        remaining_seconds = seconds % 60
        return f"{hours}å°æ—¶{minutes}åˆ†{remaining_seconds:.1f}ç§’"


async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    http_service_url = "http://localhost:8080"
    mcp_service_url = "http://localhost:3001/mcp"
    test_file = "tests/files/é¡¹ç›®æ±‡æŠ¥_202504.pdf"
    
    print("ğŸš€ PDFå›¾ç‰‡é“¾å¼å¤„ç†é›†æˆæµ‹è¯•")
    print(f"ğŸ“¡ HTTPæœåŠ¡: {http_service_url}")
    print(f"ğŸ“¡ MCPæœåŠ¡: {mcp_service_url}")
    print(f"ğŸ“„ æµ‹è¯•æ–‡ä»¶: {test_file}")
    print("=" * 80)
    
    # è®°å½•æ€»å¼€å§‹æ—¶é—´
    total_start_time = time.time()
    
    # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶
    if not Path(test_file).exists():
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        sys.exit(1)
    
    try:
        # æ­¥éª¤1: ä¸Šä¼ PDFæ–‡ä»¶åˆ°HTTPæœåŠ¡
        print(f"\nğŸ“¤ æ­¥éª¤1: ä¸Šä¼ PDFæ–‡ä»¶åˆ°HTTPæœåŠ¡")
        upload_start_time = time.time()
        
        with open(test_file, 'rb') as f:
            file_content = f.read()
        
        print(f"   æ–‡ä»¶å¤§å°: {len(file_content):,} å­—èŠ‚ ({len(file_content)/1024/1024:.1f} MB)")
        
        files = {
            'file': ('é¡¹ç›®æ±‡æŠ¥_202504.pdf', file_content, 'application/pdf')
        }
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(f"{http_service_url}/upload", files=files)
            response.raise_for_status()
            upload_result = response.json()
        
        upload_duration = time.time() - upload_start_time
        print(f"âœ… PDFä¸Šä¼ æˆåŠŸ! ç”¨æ—¶: {format_duration(upload_duration)}")
        print(f"   Resource ID: {upload_result.get('resource_id')}")
        print(f"   URL: {upload_result.get('url')}")
        print(f"   æ–‡ä»¶å: {upload_result.get('filename')}")
        print(f"   å¤§å°: {upload_result.get('size')} å­—èŠ‚")
        
        pdf_url = upload_result.get('url')
        if not pdf_url:
            print("âŒ æœªè·å–åˆ°PDF URL")
            sys.exit(1)
        
        # æ­¥éª¤2: é€šè¿‡MCPæœåŠ¡è§£æPDFï¼Œè·å–Markdownå†…å®¹
        print(f"\nğŸ“– æ­¥éª¤2: è§£æPDFæ–‡ä»¶ï¼Œæå–Markdownå†…å®¹")
        print(f"   PDF URL: {pdf_url}")
        
        # è®°å½•PDFè§£æå¼€å§‹æ—¶é—´
        pdf_parse_start_time = time.time()
        
        transport = StreamableHttpTransport(mcp_service_url)
        async with Client(transport) as mcp_client:
            # è§£æPDF
            result = await mcp_client.call_tool("read_local_file", {
                "urls": [{"url": pdf_url}],
                "max_size": 100  # 100MBé™åˆ¶
            })
            
            # è®°å½•PDFè§£æç»“æŸæ—¶é—´
            pdf_parse_duration = time.time() - pdf_parse_start_time
            
            if not result or len(result) == 0 or not hasattr(result[0], 'text'):
                print("âŒ MCPæœåŠ¡è¿”å›ç©ºç»“æœ")
                sys.exit(1)
            
            read_result = json.loads(result[0].text)
            contents = read_result.get('contents', [])
            failed = read_result.get('failed', [])
            
            if failed:
                print(f"âŒ PDFè§£æå¤±è´¥:")
                for failure in failed:
                    print(f"   - {failure.get('resource_id')}: {failure.get('error_message')}")
                sys.exit(1)
            
            if not contents:
                print(f"âŒ æ²¡æœ‰è¯»å–åˆ°PDFå†…å®¹")
                sys.exit(1)
            
            pdf_content = contents[0]
            markdown_text = pdf_content.get('content', '')
            content_type = pdf_content.get('content_type', 'æœªçŸ¥')
            
            print(f"âœ… PDFè§£æå®Œæˆ! ç”¨æ—¶: {format_duration(pdf_parse_duration)}")
            print(f"   å†…å®¹ç±»å‹: {content_type}")
            print(f"   å†…å®¹é•¿åº¦: {len(markdown_text):,} å­—ç¬¦")
            print(f"   è§£æé€Ÿåº¦: {len(markdown_text)/pdf_parse_duration:.0f} å­—ç¬¦/ç§’")
            print(f"   å†…å®¹é¢„è§ˆ:")
            print(f"   {'-' * 40}")
            print(f"   {markdown_text[:300]}...")
            print(f"   {'-' * 40}")
            
            # æ­¥éª¤3: ä»Markdownä¸­æå–å›¾ç‰‡é“¾æ¥
            print(f"\nğŸ–¼ï¸  æ­¥éª¤3: ä»Markdownä¸­æå–å›¾ç‰‡é“¾æ¥")
            image_extract_start_time = time.time()
            
            image_links = extract_image_links(markdown_text)
            
            image_extract_duration = time.time() - image_extract_start_time
            
            if not image_links:
                print(f"âŒ æœªåœ¨Markdownä¸­æ‰¾åˆ°å›¾ç‰‡é“¾æ¥")
                print(f"   æ£€æŸ¥Markdownå†…å®¹ç‰‡æ®µ:")
                # æŸ¥æ‰¾å¯èƒ½çš„å›¾ç‰‡å¼•ç”¨æ¨¡å¼
                img_patterns = re.findall(r'!\[.*?\]\([^)]+\)', markdown_text)
                if img_patterns:
                    print(f"   æ‰¾åˆ°çš„å›¾ç‰‡æ¨¡å¼: {img_patterns[:3]}...")
                else:
                    print(f"   æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ¨¡å¼")
                sys.exit(1)
            
            print(f"âœ… æ‰¾åˆ° {len(image_links)} ä¸ªå›¾ç‰‡é“¾æ¥! ç”¨æ—¶: {format_duration(image_extract_duration)}")
            for i, link in enumerate(image_links[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"   {i}. {link}")
            if len(image_links) > 5:
                print(f"   ... å’Œå…¶ä»– {len(image_links) - 5} ä¸ªå›¾ç‰‡")
            
            # æ­¥éª¤4: é€šè¿‡MCPæœåŠ¡è¯»å–å›¾ç‰‡å†…å®¹ï¼ˆOCRè¯†åˆ«ï¼‰
            print(f"\nğŸ” æ­¥éª¤4: OCRè¯†åˆ«å›¾ç‰‡å†…å®¹")
            
            # é€‰æ‹©å‰3ä¸ªå›¾ç‰‡è¿›è¡ŒOCRæµ‹è¯•ï¼ˆé¿å…è¿‡é•¿æ—¶é—´ï¼‰
            test_images = image_links[:3]
            print(f"   æµ‹è¯•å›¾ç‰‡æ•°é‡: {len(test_images)}")
            
            # è®°å½•OCRå¼€å§‹æ—¶é—´
            ocr_start_time = time.time()
            
            # test_images ç°åœ¨åŒ…å«çš„æ˜¯resource_idï¼ˆæ²¡æœ‰file://å‰ç¼€ï¼‰ï¼Œéœ€è¦é‡æ–°æ·»åŠ å‰ç¼€
            image_urls = [{"url": f"file:///{link}"} for link in test_images]
            
            result = await mcp_client.call_tool("read_local_file", {
                "urls": image_urls,
                "max_size": 10  # 10MBé™åˆ¶
            })
            
            # è®°å½•OCRç»“æŸæ—¶é—´
            ocr_duration = time.time() - ocr_start_time
            
            if not result or len(result) == 0 or not hasattr(result[0], 'text'):
                print("âŒ å›¾ç‰‡OCRæœåŠ¡è¿”å›ç©ºç»“æœ")
                sys.exit(1)
            
            ocr_result = json.loads(result[0].text)
            ocr_contents = ocr_result.get('contents', [])
            ocr_failed = ocr_result.get('failed', [])
            
            print(f"âœ… OCRè¯†åˆ«å®Œæˆ! ç”¨æ—¶: {format_duration(ocr_duration)}")
            print(f"   æˆåŠŸè¯†åˆ«: {len(ocr_contents)} ä¸ªå›¾ç‰‡")
            print(f"   è¯†åˆ«å¤±è´¥: {len(ocr_failed)} ä¸ªå›¾ç‰‡")
            print(f"   å¹³å‡æ¯å›¾ç‰‡OCRæ—¶é—´: {format_duration(ocr_duration/len(test_images))}")
            
            if ocr_failed:
                print(f"\nâŒ OCRå¤±è´¥çš„å›¾ç‰‡:")
                for failure in ocr_failed:
                    print(f"   - {failure.get('resource_id')}: {failure.get('error_message')}")
            
            if ocr_contents:
                print(f"\nğŸ“ OCRè¯†åˆ«ç»“æœ:")
                total_ocr_chars = 0
                for i, content in enumerate(ocr_contents, 1):
                    resource_id = content.get('resource_id', 'æœªçŸ¥')
                    ocr_text = content.get('content', '')
                    content_type = content.get('content_type', 'æœªçŸ¥')
                    
                    print(f"\n   å›¾ç‰‡ {i}: {resource_id}")
                    print(f"   å†…å®¹ç±»å‹: {content_type}")
                    print(f"   è¯†åˆ«æ–‡å­—é•¿åº¦: {len(ocr_text)} å­—ç¬¦")
                    total_ocr_chars += len(ocr_text)
                    if ocr_text.strip():
                        print(f"   è¯†åˆ«å†…å®¹é¢„è§ˆ:")
                        print(f"   {'-' * 30}")
                        print(f"   {ocr_text[:200]}...")
                        print(f"   {'-' * 30}")
                    else:
                        print(f"   âš ï¸  æœªè¯†åˆ«åˆ°æ–‡å­—å†…å®¹")
            
            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            total_duration = time.time() - total_start_time
            
            # æœ€ç»ˆæ€»ç»“
            print(f"\nğŸ‰ å®Œæ•´é“¾å¼æµ‹è¯•æˆåŠŸ!")
            print(f"\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:")
            print(f"   ğŸ“¤ PDFä¸Šä¼ : {format_duration(upload_duration)}")
            print(f"   ğŸ“– PDFè§£æ: {format_duration(pdf_parse_duration)} ({pdf_parse_duration/total_duration*100:.1f}%)")
            print(f"   ğŸ–¼ï¸  å›¾ç‰‡æå–: {format_duration(image_extract_duration)}")
            print(f"   ğŸ” OCRè¯†åˆ«: {format_duration(ocr_duration)} ({ocr_duration/total_duration*100:.1f}%)")
            print(f"   ğŸ“Š æ€»è€—æ—¶: {format_duration(total_duration)}")
            
            print(f"\nğŸ“Š å¤„ç†ç»“æœ:")
            print(f"   âœ… PDFè§£æ: {len(markdown_text):,} å­—ç¬¦")
            print(f"   âœ… å›¾ç‰‡æå–: {len(image_links)} ä¸ªå›¾ç‰‡")
            print(f"   âœ… OCRè¯†åˆ«: {len(ocr_contents)}/{len(test_images)} æˆåŠŸ")
            
            if ocr_contents:
                total_ocr_text = sum(len(c.get('content', '')) for c in ocr_contents)
                print(f"   âœ… æ€»è¯†åˆ«æ–‡å­—: {total_ocr_text:,} å­—ç¬¦")
                print(f"   âœ… OCRæ•ˆç‡: {total_ocr_text/ocr_duration:.0f} å­—ç¬¦/ç§’")
            
            print(f"\nğŸŒŸ ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•å®Œå…¨é€šè¿‡! æ•´ä¸ªé“¾è·¯è¿è¡Œæ­£å¸¸!")
            
            # æ€§èƒ½åˆ†æ
            print(f"\nğŸ“ˆ æ€§èƒ½åˆ†æ:")
            print(f"   ğŸŒ æœ€è€—æ—¶ç¯èŠ‚: {'PDFè§£æ' if pdf_parse_duration > ocr_duration else 'OCRè¯†åˆ«'}")
            print(f"   âš¡ å¹¶å‘ä¼˜åŒ–æ•ˆæœ: ä½¿ç”¨max_workers=5è¿›è¡Œå¹¶å‘å¤„ç†")
            if pdf_parse_duration > 30:
                print(f"   ğŸ’¡ ä¼˜åŒ–å»ºè®®: PDFè§£ææ—¶é—´è¾ƒé•¿ï¼Œå¯èƒ½å› ä¸ºæ–‡æ¡£åŒ…å«å¤§é‡å›¾ç‰‡éœ€è¦æå–å’Œä¸Šä¼ ")
            
    except httpx.HTTPStatusError as e:
        print(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {e.response.status_code}")
        try:
            error_detail = e.response.json()
            print(f"   é”™è¯¯è¯¦æƒ…: {error_detail}")
        except:
            print(f"   é”™è¯¯å†…å®¹: {e.response.text}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main()) 