#!/usr/bin/env python3
"""
OSSèµ„æºè§£ææµ‹è¯•è„šæœ¬
ç›´æ¥ä½¿ç”¨ OSS ä¸Šçš„ resource_id æµ‹è¯•æ–‡ä»¶è§£æåŠŸèƒ½
resource_id å¯¹åº” tests/files ç›®å½•ä¸‹çš„æ–‡ä»¶å
"""

import asyncio
import json
import sys
from pathlib import Path
from typing import List

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

from file_reader import FileReader, ReadRequest
from file_reader.utils import get_logger


class OSSParsingTester:
    """OSSè§£ææµ‹è¯•å™¨"""
    
    def __init__(self):
        self.logger = get_logger("oss_parsing_tester")
        self.file_reader = FileReader()
        
        # è·å– tests/files ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ä½œä¸º resource_id
        self.test_files = self._get_test_files()
    
    def _get_test_files(self) -> List[str]:
        """è·å–æµ‹è¯•æ–‡ä»¶åˆ—è¡¨"""
        files_dir = Path("tests/files")
        if not files_dir.exists():
            self.logger.error(f"æµ‹è¯•æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {files_dir}")
            return []
        
        test_files = []
        for file_path in files_dir.iterdir():
            if file_path.is_file() and not file_path.name.startswith('.'):
                test_files.append(file_path.name)
        
        test_files.sort()
        return test_files
    
    async def test_single_file(self, resource_id: str, max_size: int = 50 * 1024 * 1024):
        """æµ‹è¯•å•ä¸ªæ–‡ä»¶è§£æ"""
        print(f"\n{'='*60}")
        print(f"ğŸ” æµ‹è¯•æ–‡ä»¶: {resource_id}")
        print(f"{'='*60}")
        
        try:
            # åˆ›å»ºè¯»å–è¯·æ±‚
            request = ReadRequest(
                resource_ids=[resource_id],
                max_size=max_size
            )
            
            # æ‰§è¡Œè§£æ
            response = await self.file_reader.read_files(request)
            
            # æ˜¾ç¤ºç»“æœ
            if response.contents:
                content = response.contents[0]
                print(f"âœ… è§£ææˆåŠŸ")
                print(f"ğŸ“„ èµ„æºID: {content.resource_id}")
                print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(content.content)} å­—ç¬¦")
                
                # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                if content.content:
                    preview = content.content[:200].replace('\n', '\\n')
                    if len(content.content) > 200:
                        preview += "..."
                    print(f"ğŸ”¤ å†…å®¹é¢„è§ˆ: {preview}")
                else:
                    print("âš ï¸  å†…å®¹ä¸ºç©º")
            
            if response.failed:
                failure = response.failed[0]
                print(f"âŒ è§£æå¤±è´¥")
                print(f"ğŸ“„ èµ„æºID: {failure.resource_id}")
                print(f"ğŸš« å¤±è´¥ç±»å‹: {failure.type}")
                print(f"ğŸ’­ é”™è¯¯ä¿¡æ¯: {failure.error_message}")
            
            return response
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    async def test_batch_files(self, resource_ids: List[str], max_size: int = 50 * 1024 * 1024):
        """æ‰¹é‡æµ‹è¯•æ–‡ä»¶è§£æ"""
        print(f"\n{'='*60}")
        print(f"ğŸ“¦ æ‰¹é‡æµ‹è¯• {len(resource_ids)} ä¸ªæ–‡ä»¶")
        print(f"{'='*60}")
        
        try:
            # åˆ›å»ºè¯»å–è¯·æ±‚
            request = ReadRequest(
                resource_ids=resource_ids,
                max_size=max_size
            )
            
            # æ‰§è¡Œè§£æ
            response = await self.file_reader.read_files(request)
            
            # æ˜¾ç¤ºç»Ÿè®¡
            success_count = len(response.contents)
            failure_count = len(response.failed)
            total_count = len(resource_ids)
            success_rate = (success_count / total_count) * 100 if total_count > 0 else 0
            
            print(f"\nğŸ“Š æ‰¹é‡è§£æç»“æœç»Ÿè®¡:")
            print(f"   æ€»æ–‡ä»¶æ•°: {total_count}")
            print(f"   æˆåŠŸè§£æ: {success_count}")
            print(f"   è§£æå¤±è´¥: {failure_count}")
            print(f"   æˆåŠŸç‡: {success_rate:.1f}%")
            
            # æ˜¾ç¤ºæˆåŠŸçš„æ–‡ä»¶
            if response.contents:
                print(f"\nâœ… æˆåŠŸè§£æçš„æ–‡ä»¶:")
                total_content_length = 0
                for content in response.contents:
                    print(f"   - {content.resource_id}: {len(content.content)} å­—ç¬¦")
                    total_content_length += len(content.content)
                print(f"   æ€»å†…å®¹é•¿åº¦: {total_content_length} å­—ç¬¦")
            
            # æ˜¾ç¤ºå¤±è´¥çš„æ–‡ä»¶
            if response.failed:
                print(f"\nâŒ è§£æå¤±è´¥çš„æ–‡ä»¶:")
                for failure in response.failed:
                    print(f"   - {failure.resource_id}: {failure.type} - {failure.error_message}")
            
            return response
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    async def test_by_file_type(self):
        """æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„æµ‹è¯•"""
        print(f"\n{'='*60}")
        print(f"ğŸ“‚ æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„æµ‹è¯•")
        print(f"{'='*60}")
        
        # æŒ‰æ–‡ä»¶æ‰©å±•ååˆ†ç»„
        file_groups = {}
        for file_name in self.test_files:
            ext = Path(file_name).suffix.lower()
            if ext not in file_groups:
                file_groups[ext] = []
            file_groups[ext].append(file_name)
        
        # é€ä¸ªç±»å‹æµ‹è¯•
        for ext, files in sorted(file_groups.items()):
            print(f"\nğŸ” æµ‹è¯• {ext} æ ¼å¼æ–‡ä»¶ ({len(files)} ä¸ª):")
            print(f"   æ–‡ä»¶: {', '.join(files)}")
            
            response = await self.test_batch_files(files)
            if response:
                success_count = len(response.contents)
                failure_count = len(response.failed)
                success_rate = (success_count / len(files)) * 100 if files else 0
                print(f"   ç»“æœ: {success_count}/{len(files)} æˆåŠŸ ({success_rate:.1f}%)")
    
    async def test_performance(self, max_concurrent: int = 3):
        """æ€§èƒ½æµ‹è¯•"""
        print(f"\n{'='*60}")
        print(f"âš¡ æ€§èƒ½æµ‹è¯• (æœ€å¤§å¹¶å‘: {max_concurrent})")
        print(f"{'='*60}")
        
        import time
        
        # æµ‹è¯•å¹¶å‘å¤„ç†
        start_time = time.time()
        
        # åˆ†æ‰¹å¤„ç†æ–‡ä»¶
        batch_size = max_concurrent
        all_responses = []
        
        for i in range(0, len(self.test_files), batch_size):
            batch_files = self.test_files[i:i + batch_size]
            print(f"\nå¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch_files)} ä¸ªæ–‡ä»¶")
            
            batch_start = time.time()
            response = await self.test_batch_files(batch_files)
            batch_end = time.time()
            
            if response:
                all_responses.append(response)
                batch_time = batch_end - batch_start
                print(f"æ‰¹æ¬¡å¤„ç†æ—¶é—´: {batch_time:.2f}ç§’")
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ç»Ÿè®¡æ€»ä½“ç»“æœ
        total_success = sum(len(resp.contents) for resp in all_responses)
        total_failure = sum(len(resp.failed) for resp in all_responses)
        total_files = len(self.test_files)
        
        print(f"\nğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
        print(f"   æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’")
        print(f"   æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"   æˆåŠŸè§£æ: {total_success}")
        print(f"   è§£æå¤±è´¥: {total_failure}")
        print(f"   å¹³å‡æ¯æ–‡ä»¶: {total_time/total_files:.2f}ç§’")
        print(f"   æˆåŠŸç‡: {(total_success/total_files)*100:.1f}%")
    
    def get_stats(self):
        """è·å–è§£æå™¨ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\n{'='*60}")
        print(f"ğŸ“ˆ è§£æå™¨ç»Ÿè®¡ä¿¡æ¯")
        print(f"{'='*60}")
        
        stats = self.file_reader.get_stats()
        print(json.dumps(stats, indent=2, ensure_ascii=False))
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸ§ª OSSèµ„æºè§£æç»¼åˆæµ‹è¯•")
        print("=" * 80)
        
        if not self.test_files:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ–‡ä»¶")
            return
        
        print(f"ğŸ“‚ æ‰¾åˆ° {len(self.test_files)} ä¸ªæµ‹è¯•æ–‡ä»¶:")
        for i, file_name in enumerate(self.test_files, 1):
            print(f"   {i:2d}. {file_name}")
        
        # 1. å•æ–‡ä»¶æµ‹è¯•ï¼ˆé€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§æ–‡ä»¶ï¼‰
        print(f"\nğŸ” å•æ–‡ä»¶è¯¦ç»†æµ‹è¯•:")
        representative_files = self.test_files[:3]  # æµ‹è¯•å‰3ä¸ªæ–‡ä»¶
        for file_name in representative_files:
            await self.test_single_file(file_name)
        
        # 2. æ‰¹é‡æµ‹è¯•
        await self.test_batch_files(self.test_files)
        
        # 3. æŒ‰æ–‡ä»¶ç±»å‹æµ‹è¯•
        await self.test_by_file_type()
        
        # 4. æ€§èƒ½æµ‹è¯•
        await self.test_performance()
        
        # 5. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        self.get_stats()
        
        print(f"\n{'='*80}")
        print("ğŸ¯ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="OSSèµ„æºè§£ææµ‹è¯•è„šæœ¬")
    parser.add_argument("--file", "-f", help="æµ‹è¯•æŒ‡å®šæ–‡ä»¶")
    parser.add_argument("--batch", "-b", action="store_true", help="æ‰¹é‡æµ‹è¯•æ‰€æœ‰æ–‡ä»¶")
    parser.add_argument("--type", "-t", help="æµ‹è¯•æŒ‡å®šæ–‡ä»¶ç±»å‹ (å¦‚: .pdf)")
    parser.add_argument("--performance", "-p", action="store_true", help="æ€§èƒ½æµ‹è¯•")
    parser.add_argument("--all", "-a", action="store_true", help="è¿è¡Œæ‰€æœ‰æµ‹è¯•")
    
    args = parser.parse_args()
    
    tester = OSSParsingTester()
    
    if args.file:
        # æµ‹è¯•å•ä¸ªæ–‡ä»¶
        await tester.test_single_file(args.file)
    elif args.batch:
        # æ‰¹é‡æµ‹è¯•
        await tester.test_batch_files(tester.test_files)
    elif args.type:
        # æŒ‰ç±»å‹æµ‹è¯•
        type_files = [f for f in tester.test_files if f.lower().endswith(args.type.lower())]
        if type_files:
            await tester.test_batch_files(type_files)
        else:
            print(f"æœªæ‰¾åˆ° {args.type} ç±»å‹çš„æ–‡ä»¶")
    elif args.performance:
        # æ€§èƒ½æµ‹è¯•
        await tester.test_performance()
    elif args.all:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        await tester.run_all_tests()
    else:
        # é»˜è®¤è¿è¡Œç®€å•æµ‹è¯•
        print("ğŸ§ª OSSèµ„æºè§£æç®€å•æµ‹è¯•")
        print("ä½¿ç”¨ --help æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹")
        print(f"\nğŸ“‚ å¯ç”¨çš„æµ‹è¯•æ–‡ä»¶ ({len(tester.test_files)} ä¸ª):")
        for i, file_name in enumerate(tester.test_files, 1):
            print(f"   {i:2d}. {file_name}")
        
        # æµ‹è¯•ç¬¬ä¸€ä¸ªæ–‡ä»¶
        if tester.test_files:
            await tester.test_single_file(tester.test_files[0])


if __name__ == "__main__":
    asyncio.run(main()) 