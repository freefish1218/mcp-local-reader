#!/usr/bin/env python3
"""
å‹ç¼©æ–‡ä»¶è§£æå™¨ç›´æ¥æµ‹è¯•
ç›´æ¥æµ‹è¯•è§£æå™¨åŠŸèƒ½ï¼Œä¸ä¾èµ–å®Œæ•´çš„æ–‡ä»¶è¯»å–æµç¨‹
"""

import asyncio
import os
import sys
import tempfile
import zipfile
import json
from pathlib import Path
import pytest

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from file_reader.parsers.archive_parser import ArchiveParser


class MockStorageClient:
    """æ¨¡æ‹Ÿå­˜å‚¨å®¢æˆ·ç«¯"""
    
    def __init__(self):
        self.uploaded_files = []
        self.enabled = True

    async def upload_files_batch(self, files):
        """æ¨¡æ‹Ÿæ–‡ä»¶æ‰¹é‡ä¸Šä¼ """
        results = []
        for i, file_info in enumerate(files):
            filename = file_info.get('filename', f'file_{i}')
            file_data = file_info.get('data', b'')
            
            # æ¨¡æ‹Ÿresource_idç”Ÿæˆ
            resource_id = f"archive_file_{len(self.uploaded_files):04d}_{filename}"
            file_url = f"file:///{resource_id}"
            
            # è®°å½•ä¸Šä¼ 
            self.uploaded_files.append({
                'filename': filename,
                'size': len(file_data),
                'resource_id': resource_id
            })
            
            # è¿”å›æˆåŠŸç»“æœ
            results.append({
                'success': True,
                'url': file_url,
                'resource_id': resource_id,
                'filename': filename,
                'size': len(file_data),
                'content_type': file_info.get('content_type', 'application/octet-stream')
            })
        
        return results


async def create_test_zip():
    """åˆ›å»ºæµ‹è¯•ZIPæ–‡ä»¶"""
    print("ğŸ“¦ åˆ›å»ºæµ‹è¯•ZIPæ–‡ä»¶...")
    
    temp_dir = tempfile.mkdtemp()
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶å†…å®¹
    test_files = {
        'README.md': '''# æµ‹è¯•é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªå‹ç¼©æ–‡ä»¶è§£ææµ‹è¯•é¡¹ç›®ã€‚

## åŒ…å«æ–‡ä»¶ç±»å‹

- Markdownæ–‡æ¡£
- JSONé…ç½®
- Pythonä»£ç 
- çº¯æ–‡æœ¬æ–‡ä»¶

## ç›®å½•ç»“æ„

å‚è§ä¸‹æ–¹çš„æ–‡ä»¶åˆ—è¡¨ã€‚
''',
        'config.json': json.dumps({
            "name": "test-archive",
            "version": "1.0.0",
            "description": "å‹ç¼©æ–‡ä»¶è§£ææµ‹è¯•",
            "settings": {
                "debug": True,
                "port": 8080
            }
        }, indent=2),
        'src/main.py': '''#!/usr/bin/env python3
"""
ä¸»ç¨‹åºå…¥å£
"""

def main():
    print("Hello from archive!")
    print("è¿™æ˜¯ä»å‹ç¼©åŒ…ä¸­æå–çš„Pythonæ–‡ä»¶")
    
if __name__ == "__main__":
    main()
''',
        'docs/usage.txt': '''ä½¿ç”¨è¯´æ˜æ–‡æ¡£

1. è§£å‹å‹ç¼©åŒ…
2. é˜…è¯»README.md
3. è¿è¡Œsrc/main.py
4. æŸ¥çœ‹é…ç½®æ–‡ä»¶config.json

æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ã€‚
''',
        'data/sample.csv': '''id,name,type
1,æ–‡ä»¶A,æ–‡æ¡£
2,æ–‡ä»¶B,å›¾ç‰‡
3,æ–‡ä»¶C,è§†é¢‘
''',
    }
    
    # åˆ›å»ºæ–‡ä»¶
    for rel_path, content in test_files.items():
        file_path = Path(temp_dir) / rel_path
        file_path.parent.mkdir(parents=True, exist_ok=True)
        file_path.write_text(content, encoding='utf-8')
    
    # åˆ›å»ºZIPæ–‡ä»¶
    zip_path = Path(temp_dir) / 'test_archive.zip'
    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for rel_path in test_files.keys():
            file_path = Path(temp_dir) / rel_path
            zipf.write(file_path, rel_path)
    
    print(f"âœ… æµ‹è¯•ZIPåˆ›å»ºå®Œæˆ: {zip_path}")
    print(f"   åŒ…å« {len(test_files)} ä¸ªæ–‡ä»¶")
    print(f"   å¤§å°: {zip_path.stat().st_size} å­—èŠ‚")
    
    return zip_path, test_files


@pytest.mark.asyncio
async def test_archive_parser_direct():
    """ç›´æ¥æµ‹è¯•å‹ç¼©æ–‡ä»¶è§£æå™¨"""
    print("ğŸš€ å‹ç¼©æ–‡ä»¶è§£æå™¨ç›´æ¥æµ‹è¯•")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæµ‹è¯•ZIP
        zip_path, expected_files = await create_test_zip()
        
        # åˆ›å»ºæ¨¡æ‹Ÿå­˜å‚¨å®¢æˆ·ç«¯
        mock_storage = MockStorageClient()
        
        # åˆ›å»ºè§£æå™¨å¹¶è®¾ç½®å­˜å‚¨å®¢æˆ·ç«¯
        parser = ArchiveParser(storage_client=mock_storage)
        
        # è¯»å–ZIPå†…å®¹
        with open(zip_path, 'rb') as f:
            zip_content = f.read()
        
        print(f"\nğŸ“„ è§£ææ–‡ä»¶: {zip_path.name}")
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {len(zip_content):,} å­—èŠ‚")
        
        # ç›´æ¥è°ƒç”¨è§£æå™¨
        print("\nğŸ” å¼€å§‹è§£æ...")
        result = parser.parse(zip_content, '.zip')
        
        if result.success:
            print("âœ… è§£ææˆåŠŸ!")
            
            # éªŒè¯åŸºæœ¬ä¿¡æ¯
            print(f"\nğŸ“ è§£æç»“æœ:")
            print(f"   - æ–‡æ¡£ç±»å‹: {result.doc_type}")
            print(f"   - å†…å®¹é•¿åº¦: {len(result.content):,} å­—ç¬¦")
            
            # æ£€æŸ¥Markdownå†…å®¹ç»“æ„
            content = result.content
            required_sections = [
                "å‹ç¼©åŒ…å†…å®¹",
                "å‹ç¼©åŒ…ä¿¡æ¯", 
                "æ–‡ä»¶ç»“æ„",
                "æ–‡ä»¶åˆ—è¡¨"
            ]
            
            for section in required_sections:
                if section in content:
                    print(f"   âœ… åŒ…å« '{section}' éƒ¨åˆ†")
                else:
                    print(f"   âŒ ç¼ºå°‘ '{section}' éƒ¨åˆ†")
            
            # æ£€æŸ¥æ–‡ä»¶å
            missing_files = []
            for filename in expected_files.keys():
                if filename in content:
                    print(f"   âœ… æ‰¾åˆ°æ–‡ä»¶: {filename}")
                else:
                    missing_files.append(filename)
            
            if missing_files:
                print(f"   âŒ ç¼ºå°‘æ–‡ä»¶: {missing_files}")
            
            # æ£€æŸ¥å…ƒæ•°æ®
            metadata = result.metadata
            print(f"\nğŸ“‹ å…ƒæ•°æ®éªŒè¯:")
            print(f"   - è§£æå™¨: {metadata.get('parser')}")
            print(f"   - æ–‡ä»¶æ•°é‡: {metadata.get('file_count')} (æœŸæœ›: {len(expected_files)})")
            print(f"   - å‹ç¼©åŒ…å¤§å°: {metadata.get('archive_size')} å­—èŠ‚")
            print(f"   - è§£å‹åå¤§å°: {metadata.get('total_extracted_size')} å­—èŠ‚")
            print(f"   - å‹ç¼©ç‡: {metadata.get('compression_ratio')}%")
            
            # éªŒè¯æ–‡ä»¶èµ„æº
            file_resources = metadata.get('file_resources', [])
            print(f"   - æ–‡ä»¶èµ„æº: {len(file_resources)} ä¸ª")
            
            # æ£€æŸ¥ä¸Šä¼ ç»“æœ
            print(f"\nğŸ“¤ ä¸Šä¼ éªŒè¯:")
            print(f"   - ä¸Šä¼ æ–‡ä»¶æ•°: {len(mock_storage.uploaded_files)}")
            
            if mock_storage.uploaded_files:
                print("   - ä¸Šä¼ çš„æ–‡ä»¶:")
                for uploaded in mock_storage.uploaded_files[:3]:
                    print(f"     â€¢ {uploaded['filename']} ({uploaded['size']} å­—èŠ‚)")
                if len(mock_storage.uploaded_files) > 3:
                    print(f"     ... è¿˜æœ‰ {len(mock_storage.uploaded_files) - 3} ä¸ª")
            
            # æ£€æŸ¥file://é“¾æ¥
            file_links = content.count('file:///')
            print(f"   - file:///é“¾æ¥æ•°: {file_links}")
            
            # æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹æ ·ä¾‹
            print(f"\nğŸ“„ å†…å®¹æ ·ä¾‹ (å‰500å­—ç¬¦):")
            print("-" * 40)
            print(content[:500])
            if len(content) > 500:
                print("...(å†…å®¹å·²æˆªæ–­)")
            print("-" * 40)
            
            return True
            
        else:
            print(f"âŒ è§£æå¤±è´¥: {result.error}")
            return False
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†
        if 'zip_path' in locals():
            try:
                temp_dir = zip_path.parent
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
                print(f"\nğŸ§¹ å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
            except:
                pass


@pytest.mark.asyncio
async def test_error_cases():
    """æµ‹è¯•é”™è¯¯æƒ…å†µ"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•é”™è¯¯æƒ…å†µ")
    
    parser = ArchiveParser()
    
    # 1. æµ‹è¯•ä¸æ”¯æŒçš„æ ¼å¼
    print("\n1. æµ‹è¯•ä¸æ”¯æŒçš„æ ¼å¼")
    result = parser.parse(b"test content", '.xyz')
    if not result.success:
        print(f"   âœ… æ­£ç¡®æ‹’ç»: {result.error}")
    else:
        print(f"   âŒ åº”è¯¥æ‹’ç»ä¸æ”¯æŒçš„æ ¼å¼")
    
    # 2. æµ‹è¯•ç©ºå†…å®¹
    print("\n2. æµ‹è¯•ç©ºå†…å®¹")
    result = parser.parse(b"", '.zip')
    if not result.success:
        print(f"   âœ… æ­£ç¡®æ‹’ç»: {result.error}")
    else:
        print(f"   âŒ åº”è¯¥æ‹’ç»ç©ºå†…å®¹")
    
    # 3. æµ‹è¯•æŸåçš„ZIP
    print("\n3. æµ‹è¯•æŸåçš„ZIP")
    result = parser.parse(b"PK\x03\x04invalid", '.zip')
    if not result.success:
        print(f"   âœ… æ­£ç¡®å¤„ç†æŸåæ–‡ä»¶: {result.error}")
    else:
        print(f"   âŒ åº”è¯¥æ‹’ç»æŸåæ–‡ä»¶")


@pytest.mark.asyncio
async def test_file_types():
    """æµ‹è¯•æ”¯æŒçš„æ–‡ä»¶ç±»å‹"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•æ”¯æŒçš„æ–‡ä»¶ç±»å‹")
    
    parser = ArchiveParser()
    
    supported_formats = ['.zip', '.rar', '.7z', '.tar', '.gz', '.tar.gz', '.tgz']
    
    for fmt in supported_formats:
        # åªæ£€æŸ¥æ˜¯å¦è¿›å…¥è§£æé€»è¾‘ï¼ˆä¼šå¤±è´¥ä½†ä¸æ˜¯å› ä¸ºæ ¼å¼ä¸æ”¯æŒï¼‰
        result = parser.parse(b"fake content", fmt)
        if "ä¸æ”¯æŒçš„å‹ç¼©æ–‡ä»¶ç±»å‹" not in str(result.error):
            print(f"   âœ… æ”¯æŒæ ¼å¼: {fmt}")
        else:
            print(f"   âŒ ä¸æ”¯æŒæ ¼å¼: {fmt}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å‹ç¼©æ–‡ä»¶è§£æå™¨ç›´æ¥æµ‹è¯•\n")
    
    # è¿è¡Œä¸»è¦æµ‹è¯•
    success = await test_archive_parser_direct()
    
    # è¿è¡Œé”™è¯¯æµ‹è¯•
    await test_error_cases()
    
    # è¿è¡Œæ ¼å¼æµ‹è¯•
    await test_file_types()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ å‹ç¼©æ–‡ä»¶è§£æå™¨æµ‹è¯•é€šè¿‡!")
    else:
        print("âŒ å‹ç¼©æ–‡ä»¶è§£æå™¨æµ‹è¯•å¤±è´¥!")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
