#!/usr/bin/env python3
"""
å‹ç¼©æ–‡ä»¶å¤„ç†é›†æˆæµ‹è¯•
æµ‹è¯•å‹ç¼©æ–‡ä»¶è§£æå™¨ä¸å­˜å‚¨æœåŠ¡çš„å®Œæ•´é›†æˆ
"""

import asyncio
import os
import sys
import tempfile
import zipfile
import json
from pathlib import Path
import pytest

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from file_reader.core import FileReader
from file_reader.storage import HTTPDownloadStorageClient
from file_reader.models import ReadRequest


@pytest.mark.asyncio
async def test_http_zip_url():
    """æµ‹è¯•HTTPç½‘ç»œURLçš„ZIPæ–‡ä»¶å¤„ç†"""
    print("\n" + "=" * 80)
    print("ğŸŒ æµ‹è¯•HTTPç½‘ç»œURLçš„ZIPæ–‡ä»¶å¤„ç†")
    
    try:
        # ä½¿ç”¨ä¸€ä¸ªåŒ…å«å¤šç§æ–‡ä»¶ç±»å‹çš„çœŸå®ZIPæ–‡ä»¶URL
        # è¿™é‡Œä½¿ç”¨GitHubä¸Šçš„ç¤ºä¾‹é¡¹ç›®ZIPæ–‡ä»¶
        test_urls = [
            # GitHubé¡¹ç›®çš„ZIPä¸‹è½½é“¾æ¥ï¼ˆåŒ…å«å¤šç§æ–‡ä»¶ç±»å‹ï¼‰
            "https://github.com/microsoft/vscode-extension-samples/archive/refs/heads/main.zip",
            # å¦ä¸€ä¸ªç¤ºä¾‹é¡¹ç›®
            "https://codeload.github.com/microsoft/TypeScript/zip/refs/heads/main"
        ]
        
        # åˆ›å»ºçœŸå®çš„HTTPå­˜å‚¨å®¢æˆ·ç«¯
        storage_client = HTTPDownloadStorageClient()
        
        # åˆ›å»ºæ–‡ä»¶è¯»å–å™¨ï¼Œä¼ å…¥çœŸå®å­˜å‚¨å®¢æˆ·ç«¯
        file_reader = FileReader(storage_client=storage_client)
        
        for i, url in enumerate(test_urls[:1]):  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªURLä»¥èŠ‚çœæ—¶é—´
            print(f"\nğŸ“„ æµ‹è¯•HTTP URL {i+1}: {url}")
            print(f"ğŸ“¡ HTTPå­˜å‚¨æœåŠ¡: {storage_client.download_service_url}")
            print(f"ğŸ”— æœåŠ¡å¯ç”¨çŠ¶æ€: {storage_client.enabled}")
            
            # åˆ›å»ºè¯»å–è¯·æ±‚ï¼Œç›´æ¥ä½¿ç”¨HTTP URL
            request = ReadRequest(
                resource_ids=[url],
                max_size=50 * 1024 * 1024  # 50MBï¼Œè€ƒè™‘åˆ°ç½‘ç»œä¸‹è½½çš„æ–‡ä»¶å¯èƒ½è¾ƒå¤§
            )
            
            # æ‰§è¡Œè¯»å–
            print(f"\nğŸ” å¼€å§‹ä¸‹è½½å’Œè§£æç½‘ç»œZIPæ–‡ä»¶...")
            print(f"   - ä¸‹è½½URL: {url}")
            
            response = await file_reader.read_files(request)
            
            # éªŒè¯ç»“æœ
            print(f"âœ… è§£æå®Œæˆ")
            print(f"   - æˆåŠŸå†…å®¹æ•°: {len(response.contents)}")
            print(f"   - å¤±è´¥æ–‡ä»¶æ•°: {len(response.failed)}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„å†…å®¹
            if response.contents:
                file_content = response.contents[0]  # è·å–ç¬¬ä¸€ä¸ªæˆåŠŸçš„å†…å®¹
                print(f"\nğŸ“ è§£æç»“æœ:")
                print(f"   - èµ„æºID: {file_content.resource_id}")
                print(f"   - å†…å®¹é•¿åº¦: {len(file_content.content):,} å­—ç¬¦")
                
                # æ£€æŸ¥Markdownå†…å®¹æ ¼å¼
                content = file_content.content
                print(f"\nğŸ“‹ Markdownæ ¼å¼æ£€æŸ¥:")
                
                # æ£€æŸ¥åŸºæœ¬ç»“æ„
                checks = [
                    ("å‹ç¼©åŒ…å†…å®¹" in content, "åŒ…å«å‹ç¼©åŒ…æ ‡é¢˜"),
                    ("æ–‡ä»¶ç»“æ„" in content, "åŒ…å«æ–‡ä»¶ç»“æ„"),
                    ("æ–‡ä»¶åˆ—è¡¨" in content, "åŒ…å«æ–‡ä»¶åˆ—è¡¨"),
                    ("##" in content, "åŒ…å«Markdownæ ‡é¢˜"),
                    ("```" in content, "åŒ…å«ä»£ç å—"),
                    ("file:///" in content, "åŒ…å«æ–‡ä»¶é“¾æ¥")
                ]
                
                for check_result, description in checks:
                    status = "âœ…" if check_result else "âŒ"
                    print(f"   - {status} {description}")
                
                # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                print(f"\nğŸ“– å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦):")
                print("-" * 60)
                print(content[:500])
                if len(content) > 500:
                    print("...")
                print("-" * 60)
                
                # æ£€æŸ¥å…ƒæ•°æ®
                metadata = file_content.metadata if hasattr(file_content, 'metadata') else {}
                print(f"\nğŸ“Š å…ƒæ•°æ®ä¿¡æ¯:")
                print(f"   - è§£æå™¨: {metadata.get('parser', 'N/A')}")
                print(f"   - æ–‡ä»¶æ•°é‡: {metadata.get('file_count', 'N/A')}")
                print(f"   - å‹ç¼©åŒ…å¤§å°: {metadata.get('archive_size', 'N/A')} å­—èŠ‚")
                print(f"   - è§£å‹åå¤§å°: {metadata.get('total_extracted_size', 'N/A')} å­—èŠ‚")
                print(f"   - å‹ç¼©ç‡: {metadata.get('compression_ratio', 'N/A')}%")
                print(f"   - æ–‡ä»¶ç±»å‹åˆ†å¸ƒ: {metadata.get('file_type_distribution', {})}")
                
                # æ£€æŸ¥æ–‡ä»¶é“¾æ¥
                if storage_client.enabled:
                    import re
                    links = re.findall(r'file:///([^\)]+)', content)
                    if links:
                        print(f"\nğŸ”— èµ„æºé“¾æ¥åˆ†æ:")
                        print(f"   - é“¾æ¥æ•°é‡: {len(links)}")
                        print(f"   - ç¤ºä¾‹é“¾æ¥: {links[0][:50]}...")
                        
                        # éªŒè¯é“¾æ¥æ ¼å¼
                        valid_links = sum(1 for link in links 
                                        if re.match(r'^\d{8}_[a-f0-9]{8}_[a-f0-9]{32}\.\w+$', link))
                        print(f"   - æœ‰æ•ˆé“¾æ¥æ ¼å¼: {valid_links}/{len(links)}")
                        
                        if valid_links > 0:
                            print(f"   - âœ… HTTPä¸‹è½½å’Œresource_idå¤„ç†æ­£ç¡®")
                        else:
                            print(f"   - âš ï¸  é“¾æ¥æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ")
                else:
                    print(f"   - âš ï¸  HTTPå­˜å‚¨æœåŠ¡æœªå¯ç”¨")
                
                print(f"\nâœ… HTTP ZIPæ–‡ä»¶å¤„ç†æˆåŠŸ")
                return True
                
            # æ£€æŸ¥å¤±è´¥çš„æ–‡ä»¶
            elif response.failed:
                print(f"\nâŒ HTTP ZIPæ–‡ä»¶å¤„ç†å¤±è´¥:")
                for failed in response.failed:
                    print(f"   - {failed.resource_id}: {failed.type}")
                    print(f"     é”™è¯¯: {failed.error_message}")
                return False
            else:
                print(f"âŒ æ²¡æœ‰è¿”å›ä»»ä½•å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯")
                return False
                
    except Exception as e:
        print(f"âŒ HTTP ZIPæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


@pytest.mark.asyncio
async def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\n" + "=" * 80)
    print("ğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†")

    # ä½¿ç”¨çœŸå®çš„HTTPå­˜å‚¨å®¢æˆ·ç«¯
    storage_client = HTTPDownloadStorageClient()
    file_reader = FileReader(storage_client=storage_client)

    # æµ‹è¯•æŸåçš„ZIPæ–‡ä»¶
    print("\n1. æµ‹è¯•æŸåçš„ZIPæ–‡ä»¶")

    # åˆ›å»ºä¸€ä¸ªæŸåçš„ZIPæ–‡ä»¶
    temp_corrupt = tempfile.NamedTemporaryFile(suffix='.zip', delete=False)
    temp_corrupt.write(b"PK\x03\x04invalid zip content")
    temp_corrupt.close()

    request = ReadRequest(
        resource_ids=[f"file://{temp_corrupt.name}"],
        max_size=1024 * 1024
    )

    response = await file_reader.read_files(request)

    if response.failed:
        print(f"   âœ… æ­£ç¡®å¤„ç†æŸåæ–‡ä»¶: {response.failed[0].error_message}")
    elif response.contents:
        print(f"   âŒ åº”è¯¥æ‹’ç»æŸåæ–‡ä»¶ï¼Œä½†è§£ææˆåŠŸäº†")
    else:
        print(f"   âŒ æ²¡æœ‰è¿”å›ä»»ä½•å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯")

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try:
        os.unlink(temp_corrupt.name)
    except:
        pass

    # æµ‹è¯•ç©ºZIPæ–‡ä»¶
    print("\n2. æµ‹è¯•ç©ºZIPæ–‡ä»¶")
    temp_empty = tempfile.NamedTemporaryFile(suffix='.zip', delete=False)
    temp_empty.close()  # åˆ›å»ºç©ºæ–‡ä»¶

    empty_request = ReadRequest(
        resource_ids=[f"file://{temp_empty.name}"],
        max_size=1024 * 1024
    )

    response = await file_reader.read_files(empty_request)

    if response.failed:
        print(f"   âœ… æ­£ç¡®å¤„ç†ç©ºæ–‡ä»¶: {response.failed[0].error_message}")
    elif response.contents:
        print(f"   âŒ åº”è¯¥æ‹’ç»ç©ºæ–‡ä»¶ï¼Œä½†è§£ææˆåŠŸäº†")
    else:
        print(f"   âŒ æ²¡æœ‰è¿”å›ä»»ä½•å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯")

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try:
        os.unlink(temp_empty.name)
    except:
        pass


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å¼€å§‹å‹ç¼©æ–‡ä»¶å¤„ç†é›†æˆæµ‹è¯•\n")
    
    # è¿è¡ŒHTTP ZIP URLæµ‹è¯•
    print("=" * 80)
    print("ğŸŒ HTTPç½‘ç»œZIPæ–‡ä»¶æµ‹è¯•")
    http_success = await test_http_zip_url()
        
    # è¿è¡Œé”™è¯¯å¤„ç†æµ‹è¯•
    await test_error_handling()
    
    print("\n" + "=" * 80)
    if http_success:
        print("ğŸ‰ HTTP ZIPæµ‹è¯•é€šè¿‡ï¼Œä½†æœ¬åœ°é›†æˆæµ‹è¯•å¤±è´¥!")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥!")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
